    <part xml:id="part-data-wrangling">
      <title>Data Wrangling</title>

      <chapter xml:id="ch-reshaping-data">
        <title>Reshaping data</title>
        
          <p>As we have seen through the book, having data in <em>tidy</em> format is what makes the tidyverse flow. After the first step in the data analysis process, importing data, a common next step is to reshape the data into a form that facilitates the rest of the analysis. The <alert>tidyr</alert> package, part of <alert>tidyverse</alert>, includes several functions that are useful for tidying data.</p>

          <p>We will use the fertility wide format dataset described in <xref ref="sec-tidy-data"/> as an example in this section.</p>

          <sage language="r">
            <input>
library(tidyverse) 
library(dslabs)
path &lt;- system.file("extdata", package = "dslabs")
filename &lt;- file.path(path, "fertility-two-countries-example.csv")
wide_data &lt;- read_csv(filename)
            </input>
          </sage>

        <section xml:id="sec-pivot-longer">
          <title>`pivot_longer`</title>

          <p>One of the most used functions in the <alert>tidyr</alert> package is <c>pivot_longer</c>, which is useful for converting wide data into tidy data.</p>

          <p>As with most tidyverse functions, the <c>pivot_longer</c> function's first argument is the data frame that will be converted. Here we want to reshape the <c>wide_data</c> dataset so that each row represents a fertility observation, which implies we need three columns to store the year, country, and the observed value. In its current form, data from different years are in different columns with the year values stored in the column names. Through the <c>names_to</c> and <c>values_to</c> argument we will tell <c>pivot_longer</c> the column names we want to assign to the columns containing the current column names and observations, respectively. The default names are <c>name</c> and <c>value</c>, which are often usable choices. In this case a better choice for these two arguments would be <c>year</c> and <c>fertility</c>. Note that nowhere in the data file does it tell us this is fertility data. Instead, we deciphered this from the file name. Through <c>cols</c>, the second argument, we specify the columns containing observed values; these are the columns that will be <em>pivoted</em>. The default is to pivot all columns so, in most cases, we have to specify the columns. In our example we want columns <c>1960</c>, <c>1961</c> up to <c>2015</c>.</p>

          <p>The code to pivot the fertility data therefore looks like this:</p>

          <sage language="r">
            <input>
new_tidy_data &lt;- wide_data |&gt;
  pivot_longer(`1960`:`2015`, names_to = "year", values_to = "fertility")
            </input>
          </sage>

          <p>We can see that the data have been converted to tidy format with columns <c>year</c> and <c>fertility</c></p>

          <sage language="r">
            <input>
head(new_tidy_data)
            </input>
          </sage>

          <p>and that each year resulted in two rows since we have two countries and this column was not pivoted. A somewhat quicker way to write this code is to specify which column will <alert>not</alert> include in the pivot, rather than all the columns that will be pivoted:</p>

          <sage language="r">
            <input>
new_tidy_data &lt;- wide_data |&gt;
  pivot_longer(-country, names_to = "year", values_to = "fertility")
            </input>
          </sage>

          <p>The <c>new_tidy_data</c> object looks like the original <c>tidy_data</c> we defined this way</p>

          <sage language="r">
            <input>
tidy_data &lt;- gapminder |&gt; 
  filter(country %in% c("South Korea", "Germany") &amp; !is.na(fertility)) |&gt;
  select(country, year, fertility)
            </input>
          </sage>

          <p>with just one minor difference. Can you spot it? Look at the data type of the year column. The <c>pivot_longer</c> function assumes that column names are characters. So we need a bit more wrangling before we are ready to make a plot. We need to convert the year column to be numbers:</p>

          <sage language="r">
            <input>
new_tidy_data &lt;- wide_data |&gt;
  pivot_longer(-country, names_to = "year", values_to = "fertility") |&gt;
  mutate(year = as.integer(year))
            </input>
          </sage>

          <p>Now that the data is tidy, we can use this relatively simple ggplot code:</p>

          <sage language="r">
            <input>
new_tidy_data |&gt; 
  ggplot(aes(year, fertility, color = country)) + 
  geom_point()
            </input>
          </sage>

        </section>

        <section xml:id="sec-pivot-wider">
          <title>`pivot_wider`</title>

          <p>As we will see in later examples, it is sometimes useful for data wrangling purposes to convert tidy data into wide data. We often use this as an intermediate step in tidying up data. The <c>pivot_wider</c> function is basically the inverse of <c>pivot_longer</c>. The first argument is for the data, but since we are using the pipe, we don't show it. The <c>names_from</c> argument tells <c>pivot_wider</c> which variable will be used as the column names. The <c>values_from</c> argument specifies which variable to use to fill out the cells.</p>

          <sage language="r">
            <input>
new_wide_data &lt;- new_tidy_data |&gt; 
  pivot_wider(names_from = year, values_from = fertility)
select(new_wide_data, country, `1960`:`1967`)
            </input>
          </sage>

          <p>Similar to <c>pivot_wider</c>, <c>names_from</c> and <c>values_from</c> default to <c>name</c> and <c>value</c>.</p>

        </section>

        <section xml:id="sec-separate">
          <title>Separating variables</title>

          <p>The data wrangling shown above was simple compared to what is usually required. In our example spreadsheet files, we include an illustration that is slightly more complicated. It contains two variables: life expectancy and fertility. However, the way it is stored is not tidy and, as we will explain, not optimal.</p>

          <sage language="r">
            <input>
path &lt;- system.file("extdata", package = "dslabs")

filename &lt;- "life-expectancy-and-fertility-two-countries-example.csv"
filename &lt;-  file.path(path, filename)

raw_dat &lt;- read_csv(filename)
select(raw_dat, 1:5)
            </input>
          </sage>

          <p>First, note that the data is in wide format. Second, notice that this table includes values for two variables, fertility and life expectancy, with the column name encoding which column represents which variable. Encoding information in the column names is not recommended but, unfortunately, it is quite common. We will put our wrangling skills to work to extract this information and store it in a tidy fashion.</p>

          <p>We can start the data wrangling with the <c>pivot_longer</c> function, but we should no longer use the column name <c>year</c> for the new column since it also contains the variable type. We will call it <c>name</c>, the default, for now:</p>

          <sage language="r">
            <input>
dat &lt;- raw_dat |&gt; pivot_longer(-country)
head(dat)
            </input>
          </sage>

          <p>The result is not exactly what we refer to as tidy since each observation is associated with two, not one, rows. We want to have the values from the two variables, fertility and life expectancy, in two separate columns. The first challenge to achieve this is to separate the <c>name</c> column into the year and the variable type. Notice that the entries in this column separate the year from the variable name with an underscore:</p>

          <sage language="r">
            <input>
dat$name[1:5]
            </input>
          </sage>

          <p>Encoding multiple variables in a column name is such a common problem that the <alert>tidyr</alert> package includes function to separate these columns into two or more. The <c>separate_wider_delim</c> function takes three arguments: the name of the column to be separated, the names to be used for the new columns, and the character that separates the variables. So, a first attempt at separating the variable name from the year might be:</p>

          <sage language="r">
            <input>
dat |&gt; separate_wider_delim(name, delim = "_", 
                            names = c("year", "name"))
            </input>
          </sage>

          <p>However, this line of code will give an error. This is because the life expectancy names have three strings separated by <c>_</c> and the fertility names have two. This is a common problem so the <c>separate_wider_delim</c> function has arguments <c>too_few</c> and <c>too_many</c> to handle these situations. We see in the help file that the option <c>too_many = merge</c> <em>will merge together any additional pieces</em>. The following line does what we want:</p>

          <sage language="r">
            <input>
dat |&gt; separate_wider_delim(name, delim = "_", 
                            names = c("year", "name"), 
                            too_many = "merge")
            </input>
          </sage>

          <p>But we are not done yet. We need to create a column for each variable and change <c>year</c> to a number. As we learned, the <c>pivot_wider</c> function can do this:</p>

          <sage language="r">
            <input>
dat &lt;- dat |&gt; 
  separate_wider_delim(name, delim = "_", 
                       names = c("year", "name"), 
                       too_many = "merge") |&gt;
  pivot_wider() |&gt;
  mutate(year = as.integer(year))

dat
            </input>
          </sage>

          <p>The data is now in tidy format with one row for each observation with three variables: year, fertility, and life expectancy.</p>

          <p>Three related function are <c>separate_wider_position</c>, <c>separate_wider_regex</c>, and <c>unite</c>. <c>separate_wider_position</c> takes a width instead of delimiter. <c>separate_wider_regex</c>, described in <xref ref="sec-separate"/>_regex, provides much more control over how we separate and what we keep. The <c>unite</c> function can be thought of as the inverse of the <c>separate</c> function: it combines two columns into one.</p>

        </section>

        <section xml:id="sec-reshaping-with-data-table">
          <title>Reshaping with data.table</title>

          <p>In general, everything you can do with <alert>tidyverse</alert> can be done with <alert>data.table</alert> and base R which, although perhaps harder to read, it is often more flexible, faster, and more efficient. Here we show how the <alert>data.table</alert> approach to <c>pivot_longer</c>, <c>pivot_wider</c>, and <c>separate</c>. We will illustrate with the previously used this example:</p>

          <sage language="r">
            <input>
path &lt;- system.file("extdata", package = "dslabs")
filename &lt;- file.path(path, "fertility-two-countries-example.csv")
            </input>
          </sage>

          <subsection xml:id="subsec-pivot-longer-is-melt">
            <title>`pivot_longer` is `melt`</title>

            <p>If in <alert>tidyverse</alert> we  write</p>

            <sage language="r">
              <input>
wide_data &lt;- read_csv(filename)
new_tidy_data &lt;- wide_data |&gt;
  pivot_longer(-1, names_to = "year", values_to = "fertility")
              </input>
            </sage>

            <p>in <alert>data.table</alert> we use the <c>melt</c> function.</p>

            <sage language="r">
              <input>
#| message: false
#| warning: false
library(data.table)
dt_wide_data &lt;- fread(filename) 
dt_new_tidy_data  &lt;- melt(dt_wide_data, 
                      measure.vars = 2:ncol(dt_wide_data), 
                      variable.name = "year", 
                      value.name = "fertility")
              </input>
            </sage>

          </subsection>

          <subsection xml:id="subsec-pivot-wider-is-dcast">
            <title>`pivot_wider` is `dcast`</title>

            <p>If in <alert>tidyverse</alert> we  write</p>

            <sage language="r">
              <input>
new_wide_data &lt;- new_tidy_data |&gt; 
  pivot_wider(names_from = year, values_from = fertility)
              </input>
            </sage>

            <p>in <alert>data.table</alert> we use the <c>dcast</c> function.</p>

            <sage language="r">
              <input>
dt_new_wide_data &lt;- dcast(dt_new_tidy_data, formula = ... ~ year,
                          value.var = "fertility")
              </input>
            </sage>

          </subsection>

          <subsection xml:id="subsec-separating-variables">
            <title>Separating variables</title>

            <p>We now illustrate with this previously used example:</p>

            <sage language="r">
              <input>
path &lt;- system.file("extdata", package = "dslabs")
filename &lt;- "life-expectancy-and-fertility-two-countries-example.csv"
filename &lt;-  file.path(path, filename)
              </input>
            </sage>

            <p>In <alert>tidyverse</alert> we wrangled using</p>

            <sage language="r">
              <input>
raw_dat &lt;- read_csv(filename)
dat &lt;- raw_dat |&gt; pivot_longer(-country) |&gt;
  separate_wider_delim(name, delim = "_", names = c("year", "name"), 
                       too_many = "merge") |&gt;
  pivot_wider() |&gt;
  mutate(year = as.integer(year))
              </input>
            </sage>

            <p>In <alert>data.table</alert> we can use the <c>tstrsplit</c> function:</p>

            <sage language="r">
              <input>
dt_raw_dat &lt;- fread(filename)
dat_long &lt;- melt(dt_raw_dat, 
                 measure.vars = which(names(dt_raw_dat) != "country"), 
                 variable.name = "name", value.name = "value")
dat_long[, c("year", "name", "name2") := 
           tstrsplit(name, "_", fixed = TRUE, type.convert = TRUE)]
dat_long[is.na(name2), name2 := ""]
dat_long[, name := paste(name, name2, sep = "_")][, name2 := NULL]
dat_wide &lt;- dcast(dat_long, country + year ~ name, value.var = "value")
              </input>
            </sage>

          </subsection>

        </section>

        <section xml:id="sec-the-janitor-package">
          <title>The janitor package</title>

          <p>The <alert>janitor</alert> package includes function for some of the most common steps needed to wrangle data. These are particularly useful as these tasks that are often repetitive and time-consuming. Key features include functions for examining and cleaning column names, removing empty or duplicate rows, and converting data types. It also offers capabilities to generate frequency tables and perform cross tabulations with ease. The package is designed to work seamlessly with the  <alert>tidyverse</alert>. Here we show four examples.</p>

          <p>Spreadsheets often use names that are not compatible with programming. The most common problem is column names with spaces. The <c>clean_names()</c> function attempts to fix this and other common problems. By default it forces variable names to be lower case and with underscore instead of space. In this example we change the variable names of the object <c>dat</c> created in the previous section and then demonstrate how this function works:</p>

          <sage language="r">
            <input>
library(janitor)
names(dat) &lt;- c("Country", "Year", "Fertility",  "Life Expectancy")
clean_names(dat) |&gt; names()
            </input>
          </sage>

          <p>Another very common challenging reality is that numeric matrices are saved in spreadsheets and include a column with characters defining the row names. To fix this we have to remove the first column, but only after assigning them as vector that we will use to define rownames after converting the data frame to a matrix. The function <c>column_to_rows</c> does these operations for us and all we have to do is specify which column contains the rownames:</p>

          <sage language="r">
            <input>
data.frame(ids = letters[1:3], x = 1:3, y = 4:6) |&gt; 
  column_to_rownames("ids") |&gt;
  as.matrix() 
            </input>
          </sage>

          <p>Another common challenge is that spreadsheets include the column names as a first row. To quickly fix this we can <c>row_to_names</c>:</p>

          <sage language="r">
            <input>
x &lt;- read.csv(file.path(path, "murders.csv"), header = FALSE) |&gt; 
  row_to_names(1)
names(x)
            </input>
          </sage>

          <p>Our final example relates to finding duplicates. A very common error in the creation of spreadsheets is that rows are duplicated. The <c>get_dups</c> function finds and reports duplicate records. By default it considers all variables, but you can also specify which ones to use.</p>

          <sage language="r">
            <input>
x &lt;- bind_rows(x, x[1,])
get_dupes(x)
            </input>
          </sage>

        </section>

        <section xml:id="sec-reshaping-data-exercises">
          <title>Exercises</title>

          <ol>
            <li><p>Run the following command to define the <c>co2_wide</c> object:</p></li>
          <sage language="r">
            <input>
co2_wide &lt;- data.frame(matrix(co2, ncol = 12, byrow = TRUE)) |&gt; 
  setNames(1:12) |&gt;
  mutate(year = as.character(1959:1997))
            </input>
          </sage>

          </ol>

          <p>Use the <c>pivot_longer</c> function to wrangle this into a tidy dataset. Call the column with the CO2 measurements <c>co2</c> and call the month column <c>month</c>. Call the resulting object <c>co2_tidy</c>.</p>

          <ol>
            <li><p>Plot CO2 versus month with a different curve for each year using this code:</p></li>
          <sage language="r">
            <input>
co2_tidy |&gt; ggplot(aes(month, co2, color = year)) + geom_line()
            </input>
          </sage>

          </ol>

          <p>If the expected plot is not made, it is probably because <c>co2_tidy$month</c> is not numeric:</p>

          <sage language="r">
            <input>
class(co2_tidy$month)
            </input>
          </sage>

          <p>Rewrite your code to make sure the month column is numeric. Then make the plot.</p>

          <ol>
            <li><p>What do we learn from this plot?</p></li>
          </ol>

          <p>a.  CO2 measures increase monotonically from 1959 to 1997. b.  CO2 measures are higher in the summer and the yearly average increased from 1959 to 1997. c.  CO2 measures appear constant and random variability explains the differences. d.  CO2 measures do not have a seasonal trend.</p>

          <ol>
            <li><p>Now load the <c>admissions</c> data set, which contains admission information for men and women across six majors and keep only the admitted percentage column:</p></li>
          <sage language="r">
            <input>
load(admissions)
dat &lt;- admissions |&gt; select(-applicants)
            </input>
          </sage>

          </ol>

          <p>If we think of an observation as a major, and that each observation has two variables (men admitted percentage and women admitted percentage) then this is not tidy. Use the <c>pivot_wider</c> function to wrangle into tidy shape: one row for each major.</p>

          <ol>
            <li><p>Now we will try a more advanced wrangling challenge. We want to wrangle the admissions data so that for each major we have 4 observations: <c>admitted_men</c>, <c>admitted_women</c>, <c>applicants_men</c> and <c>applicants_women</c>. The <em>trick</em> we perform here is actually quite common: first use <c>pivot_longer</c> to generate an intermediate data frame and then <c>pivot_wider</c> to obtain the tidy data we want. We will go step by step in this and the next two exercises.</p></li>
          </ol>

          <p>Use the <c>pivot_longer</c> function to create a <c>tmp</c> data frame with a column containing the type of observation: <c>admitted</c> or <c>applicants</c>. Call the new columns <c>name</c> and <c>value</c>.</p>

          <ol>
            <li><p>Now you have an object <c>tmp</c> with columns <c>major</c>, <c>gender</c>, <c>name</c> and <c>value</c>. Note that if you combine the <c>name</c> and <c>gender</c>, we get the column names we want: <c>admitted_men</c>, <c>admitted_women</c>, <c>applicants_men</c> and <c>applicants_women</c>. Use the function <c>unite</c> to create a new column called <c>column_name</c>.</p></li>
            <li><p>Now use the <c>pivot_wider</c> function to generate the tidy data with four variables for each major.</p></li>
            <li><p>Now use the pipe to write a line of code that turns <c>admissions</c> to the table produced in the previous exercise.</p></li>
          </ol>

        </section>
        
      </chapter>

      <chapter xml:id="ch-joining-tables">
        <title>Joining tables</title>
        
          <p>The information we need for a given analysis may not be just in one table. Here we use a simple examples to illustrate the general challenge of combining tables.</p>

          <p>Suppose we want to explore the relationship between population size for US states and electoral votes. We have the population size in this table:</p>

          <sage language="r">
            <input>
library(tidyverse)
library(dslabs)
head(murders)
            </input>
          </sage>

          <p>and electoral votes in this one:</p>

          <sage language="r">
            <input>
head(results_us_election_2016)
            </input>
          </sage>

          <p>Just concatenating these two tables together will not work since the order of the states is not the same.</p>

          <sage language="r">
            <input>
identical(results_us_election_2016$state, murders$state)
            </input>
          </sage>

          <p>The <em>join</em> functions, described below, are designed to handle this challenge.</p>

        <section xml:id="sec-joins">
          <title>Joins</title>

          <p>The <em>join</em> functions in the __dplyr__ package make sure that the tables are combined so that matching rows are together. If you know SQL, you will see that the approach and syntax is very similar. The general idea is that one needs to identify one or more columns that will serve to match the two tables. Then a new table with the combined information is returned. Notice what happens if we join the two tables above by state using <c>left_join</c> (we will remove the <c>others</c> column and rename <c>electoral_votes</c> so that the tables fit on the page):</p>

          <sage language="r">
            <input>
tab &lt;- left_join(murders, results_us_election_2016, by = "state") |&gt;
  select(-others) |&gt; rename(ev = electoral_votes)
head(tab)
            </input>
          </sage>

          <p>The data has been successfully joined and we can now, for example, make a plot to explore the relationship:</p>

          <sage language="r">
            <input>
library(ggrepel)
tab |&gt; ggplot(aes(population/10^6, ev, label = abb)) +
  geom_point() +
  scale_x_log10() + scale_y_log10() +
  geom_text_repel() + 
  geom_smooth(method = "lm", se = FALSE)
            </input>
          </sage>

          <p>We see the relationship is close to linear with about 2 electoral votes for every million persons, but with very small states getting higher ratios.</p>

          <p>In practice, it is not always the case that each row in one table has a matching row in the other. For this reason, we have several versions of join. To illustrate this challenge, we will take subsets of the tables above. We create the tables <c>tab1</c> and <c>tab2</c> so that they have some states in common but not all:</p>

          <sage language="r">
            <input>
tab_1 &lt;- slice(murders, 1:6) |&gt; select(state, population)
tab_2 &lt;- results_us_election_2016 |&gt; 
  filter(state %in% c("Alabama", "Alaska", "Arizona", 
                    "California", "Connecticut", "Delaware")) |&gt; 
  select(state, electoral_votes) |&gt; rename(ev = electoral_votes)
            </input>
          </sage>

          <p>We will use these two tables as examples in the next sections.</p>

          <subsection xml:id="subsec-left-join">
            <title>Left join</title>

            <p>Suppose we want a table like <c>tab_1</c>, but adding electoral votes to whatever states we have available. For this, we use <c>left_join</c> with <c>tab_1</c> as the first argument. We specify which column to use to match with the <c>by</c> argument.</p>

            <sage language="r">
              <input>
left_join(tab_1, tab_2, by = "state")
              </input>
            </sage>

            <p>Note that <c>NA</c>s are added to the two states not appearing in <c>tab_2</c>. Also, notice that this function, as well as all the other joins, can receive the first arguments through the pipe:</p>

            <sage language="r">
              <input>
tab_1 |&gt; left_join(tab_2, by = "state")
              </input>
            </sage>

          </subsection>

          <subsection xml:id="subsec-right-join">
            <title>Right join</title>

            <p>If instead of a table with the same rows as first table, we want one with the same rows as second table, we can use <c>right_join</c>:</p>

            <sage language="r">
              <input>
tab_1 |&gt; right_join(tab_2, by = "state")
              </input>
            </sage>

            <p>Now the NAs are in the column coming from <c>tab_1</c>.</p>

          </subsection>

          <subsection xml:id="subsec-inner-join">
            <title>Inner join</title>

            <p>If we want to keep only the rows that have information in both tables, we use <c>inner_join</c>. You can think of this as an intersection:</p>

            <sage language="r">
              <input>
inner_join(tab_1, tab_2, by = "state")
              </input>
            </sage>

          </subsection>

          <subsection xml:id="subsec-full-join">
            <title>Full join</title>

            <p>If we want to keep all the rows and fill the missing parts with NAs, we can use <c>full_join</c>. You can think of this as a union:</p>

            <sage language="r">
              <input>
full_join(tab_1, tab_2, by = "state")
              </input>
            </sage>

          </subsection>

          <subsection xml:id="subsec-semi-join">
            <title>Semi join</title>

            <p>The <c>semi_join</c> function lets us keep the part of first table for which we have information in the second. It does not add the columns of the second:</p>

            <sage language="r">
              <input>
semi_join(tab_1, tab_2, by = "state")
              </input>
            </sage>

          </subsection>

          <subsection xml:id="subsec-anti-join">
            <title>Anti join</title>

            <p>The function <c>anti_join</c> is the opposite of <c>semi_join</c>. It keeps the elements of the first table for which there is no information in the second:</p>

            <sage language="r">
              <input>
anti_join(tab_1, tab_2, by = "state")
              </input>
            </sage>

            <p>The following diagram summarizes the above joins:</p>

            <figure>
              <image source="wrangling/img/joins.png"/>
            </figure>

            <p>(Image courtesy of RStudio. CC-BY-4.0 license. Cropped from original.)</p>

          </subsection>

        </section>

        <section xml:id="sec-binding">
          <title>Binding</title>

          <p>Although we have yet to use it in this book, another common way in which datasets are combined is by <em>binding</em> them. Unlike the join function, the binding functions do not try to match by a variable, but instead simply combine datasets. If the datasets don't match by the appropriate dimensions, one obtains an error.</p>

          <subsection xml:id="subsec-binding-columns">
            <title>Binding columns</title>

            <p>The __dplyr__ function _bind_cols_ binds two objects by making them columns in a tibble. For example, we quickly want to make a data frame consisting of numbers we can use</p>

            <sage language="r">
              <input>
bind_cols(a = 1:3, b = 4:6)
              </input>
            </sage>

            <p>This function requires that we assign names to the columns. Here we chose <c>a</c> and <c>b</c>.</p>

            <p>Note that there is an R-base function <c>cbind</c> with the exact same functionality. An important difference is that <c>cbind</c> can create different types of objects, while <c>bind_cols</c> always produces a data frame.</p>

            <p><c>bind_cols</c> can also bind two different data frames. For example, here we break up the <c>tab</c> data frame and then bind them back together:</p>

            <sage language="r">
              <input>
tab_1 &lt;- tab[, 1:3]
tab_2 &lt;- tab[, 4:6]
tab_3 &lt;- tab[, 7:8]
new_tab &lt;- bind_cols(tab_1, tab_2, tab_3)
head(new_tab)
              </input>
            </sage>

          </subsection>

          <subsection xml:id="subsec-binding-by-rows">
            <title>Binding by rows</title>

            <p>The <c>bind_rows</c> function is similar to <c>bind_cols</c>, but binds rows instead of columns:</p>

            <sage language="r">
              <input>
tab_1 &lt;- tab[1:2,]
tab_2 &lt;- tab[3:4,]
bind_rows(tab_1, tab_2)
              </input>
            </sage>

            <p>This is based on an R-base function <c>rbind</c>.</p>

          </subsection>

        </section>

        <section xml:id="sec-set-operators">
          <title>Set operators</title>

          <p>Another set of commands useful for combining datasets are the set operators. When applied to vectors, these behave as their names suggest. Examples are <c>intersect</c>, <c>union</c>, <c>setdiff</c>, and <c>setequal</c>. However, if the __tidyverse__, or  more specifically __dplyr__, is loaded, these functions can be used on data frames as opposed to just on vectors.</p>

          <subsection xml:id="subsec-intersect">
            <title>Intersect</title>

            <p>You can take intersections of vectors of any type, such as numeric:</p>

            <sage language="r">
              <input>
intersect(1:10, 6:15)
              </input>
            </sage>

            <p>or characters:</p>

            <sage language="r">
              <input>
intersect(c("a","b","c"), c("b","c","d"))
              </input>
            </sage>

            <p>The __dplyr__ package includes an <c>intersect</c> function that can be applied to tables with the same column names. This function returns the rows in common between two tables. To make sure we use the __dplyr__ version of <c>intersect</c> rather than the base R version, we can use <c>dplyr::intersect</c> like this:</p>

            <sage language="r">
              <input>
tab_1 &lt;- tab[1:5,]
tab_2 &lt;- tab[3:7,]
dplyr::intersect(tab_1, tab_2)
              </input>
            </sage>

          </subsection>

          <subsection xml:id="subsec-union">
            <title>Union</title>

            <p>Similarly <em>union</em> takes the union of vectors. For example:</p>

            <sage language="r">
              <input>
union(1:10, 6:15)
union(c("a","b","c"), c("b","c","d"))
              </input>
            </sage>

            <p>The __dplyr__ package includes a version of <c>union</c> that combines all the rows of two tables with the same column names.</p>

            <sage language="r">
              <input>
tab_1 &lt;- tab[1:5,]
tab_2 &lt;- tab[3:7,]
dplyr::union(tab_1, tab_2) 
              </input>
            </sage>

          </subsection>

          <subsection xml:id="subsec-setdiff">
            <title>`setdiff`</title>

            <p>The set difference between a first and second argument can be obtained with <c>setdiff</c>. Unlike <c>intersect</c> and <c>union</c>, this function is not symmetric:</p>

            <sage language="r">
              <input>
setdiff(1:10, 6:15)
setdiff(6:15, 1:10)
              </input>
            </sage>

            <p>As with the functions shown above, __dplyr__ has a version for data frames:</p>

            <sage language="r">
              <input>
tab_1 &lt;- tab[1:5,]
tab_2 &lt;- tab[3:7,]
dplyr::setdiff(tab_1, tab_2)
              </input>
            </sage>

          </subsection>

          <subsection xml:id="subsec-setequal">
            <title>`setequal`</title>

            <p>Finally, the function <c>setequal</c> tells us if two sets are the same, regardless of order. So notice that:</p>

            <sage language="r">
              <input>
setequal(1:5, 1:6)
              </input>
            </sage>

            <p>but:</p>

            <sage language="r">
              <input>
setequal(1:5, 5:1)
              </input>
            </sage>

            <p>The __dplyr__ version checks whether data frames are equal, regardless of order of rows <em>or</em> columns:</p>

            <sage language="r">
              <input>
dplyr::setequal(tab_1, tab_2)
              </input>
            </sage>

          </subsection>

        </section>

        <section xml:id="sec-joining-with-data-table">
          <title>Joining with data.table</title>

          <p>The <alert>data.table</alert> package includes <c>merge</c>, a very efficient function for joining tables.</p>

          <p>In <alert>tidyverse</alert> we joined two tables with <c>left_join</c>:</p>

          <sage language="r">
            <input>
tab &lt;- left_join(murders, results_us_election_2016, by = "state") 
            </input>
          </sage>

          <p>In <alert>data.table</alert> the <c>merge</c> functions works similarly:</p>

          <sage language="r">
            <input>
#| message: false
#| warning: false
library(data.table)
tab &lt;- merge(murders, results_us_election_2016, by = "state", all.x = TRUE)
            </input>
          </sage>

          <p>Instead of defining different functions for the different type of joins, <c>merge</c> uses the the logical arguments <c>all</c> (full join), <c>all.x</c> (left join), and <c>all.y</c> (right join).</p>

        </section>

        <section xml:id="sec-joining-tables-exercises">
          <title>Exercises</title>

          <ol>
            <li><p>Install and load the __Lahman__ library. This database includes data related to baseball teams. It includes summary statistics about how the players performed on offense and defense for several years. It also includes personal information about the players.</p></li>
          </ol>

          <p>The <c>Batting</c> data frame contains the offensive statistics for all players for many years. You can see, for example, the top 10 hitters by running this code:</p>

          <sage language="r">
            <input>
library(Lahman)

top &lt;- Batting |&gt; 
  filter(yearID == 2016) |&gt;
  arrange(desc(HR)) |&gt;
  slice(1:10)

top |&gt; as_tibble()
            </input>
          </sage>

          <p>But who are these players? We see an ID, but not the names. The player names are in this table</p>

          <sage language="r">
            <input>
People |&gt; as_tibble()
            </input>
          </sage>

          <p>We can see column names <c>nameFirst</c> and <c>nameLast</c>. Use the <c>left_join</c> function to create a table of the top home run hitters. The table should have <c>playerID</c>, first name, last name, and number of home runs (HR).  Rewrite the object <c>top</c> with this new table.</p>

          <ol>
            <li><p>Now use the <c>Salaries</c> data frame to add each player's salary to the table you created in exercise 1. Note that salaries are different every year so make sure to filter for the year 2016, then use <c>right_join</c>. This time show first name, last name, team, HR, and salary.</p></li>
            <li><p>In a previous exercise, we created a tidy version of the <c>co2</c> dataset:</p></li>
          <sage language="r">
            <input>
co2_wide &lt;- data.frame(matrix(co2, ncol = 12, byrow = TRUE)) |&gt; 
  setNames(1:12) |&gt;
  mutate(year = 1959:1997) |&gt;
  pivot_longer(-year, names_to = "month", values_to = "co2") |&gt;
  mutate(month = as.numeric(month))
            </input>
          </sage>

          </ol>

          <p>We want to see if the monthly trend is changing, so we are going to remove the year effects and then plot the results. We will first compute the year averages. Use the <c>group_by</c> and <c>summarize</c> to compute the average co2 for each year. Save in an object called <c>yearly_avg</c>.</p>

          <ol>
            <li><p>Now use the <c>left_join</c> function to add the yearly average to the <c>co2_wide</c> dataset. Then compute the residuals: observed co2 measure - yearly average.</p></li>
            <li><p>Make a plot of the seasonal trends by year but only after removing the year effect.</p></li>
          </ol>

        </section>
        
      </chapter>

      <chapter xml:id="ch-parsing-dates-and-times">
        <title>Parsing dates and times</title>
        
          <p>We have described three main types of vectors: numeric, character, and logical. When analyzing data, we often encounter variables that are dates. Although we can represent a date with a string, for example <c>November 2, 2017</c>, once we pick a reference day, referred to as the <em>epoch</em> by computer programmers, they can be converted to numbers by calculating the number of days since the epoch. In R and Unix, the epoch is defined as January 1, 1970. So, for example, January 2, 1970 is day 1, December 31, 1969 is day -1, and November 2, 2017, is day 17,204.</p>

          <p>Now how should we represent dates and times when analyzing data in R? We could just use days since the epoch, but then it is almost impossible to interpret. If I tell you it's November 2, 2017, you know what this means immediately. If I tell you it's day 17,204, you will be quite confused. Similar problems arise with times and even more complications can appear due to time zones. For this reason, R defines a data type just for dates and times.</p>

        <section xml:id="sec-the-date-data-type">
          <title>The date data type</title>

          <p>We can see an example of the data type R uses for data here:</p>

          <sage language="r">
            <input>
library(tidyverse)
library(dslabs)
polls_us_election_2016$startdate |&gt; head()
            </input>
          </sage>

          <p>The dates look like strings, but they are not:</p>

          <sage language="r">
            <input>
class(polls_us_election_2016$startdate)
            </input>
          </sage>

          <p>Look at what happens when we convert them to numbers:</p>

          <sage language="r">
            <input>
as.numeric(polls_us_election_2016$startdate) |&gt; head()
            </input>
          </sage>

          <p>It turns them into days since the epoch. The <c>as.Date</c> function can convert a character into a date. So to see that the epoch is day 0 we can type</p>

          <sage language="r">
            <input>
as.Date("1970-01-01") |&gt; as.numeric()
            </input>
          </sage>

          <p>Plotting functions, such as those in ggplot, are aware of the date format. This means that, for example, a scatterplot can use the numeric representation to decide on the position of the point, but include the string in the labels:</p>

          <sage language="r">
            <input>
polls_us_election_2016 |&gt; filter(pollster == "Ipsos" &amp; state == "U.S.") |&gt;
  ggplot(aes(startdate, rawpoll_trump)) +
  geom_line()
            </input>
          </sage>

          <p>Note in particular that the month names are displayed, a very convenient feature.</p>

        </section>

        <section xml:id="sec-lubridate">
          <title>The lubridate package</title>

          <p>The __lubridate__ package provides tools to work with date and times.</p>

          <sage language="r">
            <input>
library(lubridate)
            </input>
          </sage>

          <p>We will take a random sample of dates to show some of the useful things one can do:</p>

          <sage language="r">
            <input>
set.seed(2002)
dates &lt;- sample(polls_us_election_2016$startdate, 10) |&gt; sort()
dates
            </input>
          </sage>

          <p>The functions <c>year</c>, <c>month</c> and <c>day</c> extract those values:</p>

          <sage language="r">
            <input>
tibble(date = dates, month = month(dates), day = day(dates), year = year(dates))
            </input>
          </sage>

          <p>We can also extract the month labels:</p>

          <sage language="r">
            <input>
month(dates, label = TRUE)
            </input>
          </sage>

          <sage language="r">
            <input>
lubridate::month(dates, label = TRUE)
            </input>
          </sage>

          <p>Another useful set of functions are the <em>parsers</em> that convert strings into dates. The function <c>ymd</c> assumes the dates are in the format YYYY-MM-DD and tries to parse as well as possible.</p>

          <sage language="r">
            <input>
x &lt;- c(20090101, "2009-01-02", "2009 01 03", "2009-1-4",
       "2009-1, 5", "Created on 2009 1 6", "200901 !!! 07")
ymd(x)
            </input>
          </sage>

          <p>A further complication comes from the fact that dates often come in different formats in which the order of year, month, and day are different. The preferred format is to show year (with all four digits), month (two digits), and then day, or what is called the ISO 8601. Specifically we use YYYY-MM-DD so that if we order the string, it will be ordered by date. You can see the function <c>ymd</c> returns them in this format.</p>

          <p>But, what if you encounter dates such as "09/01/02"? This could be September 1, 2002 or January 2, 2009 or January 9, 2002. In these cases, examining the entire vector of dates will help you determine what format it is by process of elimination. Once you know, you can use the many parses provided by __lubridate__.</p>

          <p>For example, if the string is:</p>

          <sage language="r">
            <input>
x &lt;- "09/01/02"
            </input>
          </sage>

          <p>The <c>ymd</c> function assumes the first entry is the year, the second is the month, and the third is the day, so it converts it to:</p>

          <sage language="r">
            <input>
ymd(x)
            </input>
          </sage>

          <p>The <c>mdy</c> function assumes the first entry is the month, then the day, then the year:</p>

          <sage language="r">
            <input>
mdy(x)
            </input>
          </sage>

          <p>The <em>lubridate</em> package provides a function for every possibility. Here is the other common one:</p>

          <sage language="r">
            <input>
dmy(x)
            </input>
          </sage>

          <p>The __lubridate__ package is also useful for dealing with times. In base R, you can get the current time typing <c>Sys.time()</c>. The __lubridate__ package provides a slightly more advanced function, <c>now</c>, that permits you to define the time zone:</p>

          <sage language="r">
            <input>
now()
now("GMT")
            </input>
          </sage>

          <p>You can see all the available time zones with <c>OlsonNames()</c> function.</p>

          <p>We can also extract hours, minutes, and seconds:</p>

          <sage language="r">
            <input>
now() |&gt; hour()
now() |&gt; minute()
now() |&gt; second()
            </input>
          </sage>

          <p>The package also includes a function to parse strings into times as well as parsers for time objects that include dates:</p>

          <sage language="r">
            <input>
x &lt;- c("12:34:56")
hms(x)
x &lt;- "Nov/2/2012 12:34:56"
mdy_hms(x)
            </input>
          </sage>

          <p>This package has many other useful functions. We describe two of these here that we find particularly useful.</p>

          <p>The <c>make_date</c> function can be used to quickly create a date object. It can take up to seven arguments: year, month, day, hour, minute, seconds, and time zone defaulting to the epoch values on UTC time. To create an date object representing, for example, July 6, 2019 we write:</p>

          <sage language="r">
            <input>
make_date(2019, 7, 6)
            </input>
          </sage>

          <p>To make a vector of January 1 for the 80s we write:</p>

          <sage language="r">
            <input>
make_date(1980:1989)
            </input>
          </sage>

          <p>Another very useful function is <c>round_date</c>. It can be used to <em>round</em> dates to nearest year, quarter,  month, week, day, hour, minutes, or seconds. So if we want to group all the polls by week of the year we can do the following:</p>

          <sage language="r">
            <input>
polls_us_election_2016 |&gt; 
  mutate(week = round_date(startdate, "week")) |&gt;
  group_by(week) |&gt;
  summarize(margin = mean(rawpoll_clinton - rawpoll_trump)) |&gt;
  ggplot(aes(week, margin)) +
  geom_point()
            </input>
          </sage>

          <p>Finally, you should be aware the there are useful function for computing operations on time such a <c>difftime</c>, <c>time_length</c>, and <c>interval</c>.</p>

        </section>

        <section xml:id="sec-dates-and-times-with-data-table">
          <title>Dates and times with data.table</title>

          <p>The <alert>data.table</alert> package includes some of the same functionality as <alert>lubridate</alert>. For example, it includes the <c>month</c>, and <c>year</c> functions that are the same as those in <alert>lubridate</alert>. The equilvalent of <alert>lubridate</alert>'s <c>day</c> is <c>mday</c>:</p>

          <sage language="r">
            <input>
library(data.table)
st &lt;- as.Date("2024-03-04")
day(st)
mday(st)
            </input>
          </sage>

          <p>Other similar functions included in <alert>data.table</alert> are <c>second</c>, <c>minute</c>, <c>hour</c>, <c>yday</c>, <c>wday</c>, <c>week</c>, <c>isoweek</c> and <c>quarter</c>.</p>

          <p>The package also includes the classes <c>IDate</c> and <c>ITime</c>, which store dates and times more efficiently that <c>lubridate</c> and base R. This convenient for large files with date stamps. You can convert dates in the usual R format: using <c>as.IDate</c> and <c>as.ITime</c>. You can see this by using the <c>object.size</c> function:</p>

          <sage language="r">
            <input>
object.size(polls_us_election_2016$startdate)
object.size(as.IDate(polls_us_election_2016$startdate))
            </input>
          </sage>

        </section>

        <section xml:id="sec-parsing-dates-and-times-exercises">
          <title>Exercises</title>

          <p>For these exercises we will use the following dataset:</p>

          <sage language="r">
            <input>
#| eval: false
library(dslabs)
head(pr_death_counts)
            </input>
          </sage>

          <ol>
            <li><p>We want to make a plot of death counts versus date. Confirm that the <c>date</c> variable are in fact dates and not strings.</p></li>
            <li><p>Plot deaths versus date. </p></li>
            <li><p>What time period is represented in these data?</p></li>
            <li><p>Note that after May 31, 2018, the deaths are all 0. The data is probably not entered yet. We also see a drop off starting around May 1. Redefine <c>dat</c> to exclude observations taken on or after May 1, 2018. Then, remake the plot.</p></li>
            <li><p>Repeat the plot but use the day of the year on the x-axis instead of date.</p></li>
            <li><p>Compute the deaths per day by month.</p></li>
            <li><p>Show the deaths per days for July and for September. What do you notice?</p></li>
            <li><p>Compute deaths per week and make a plot.</p></li>
          </ol>

        </section>
        
      </chapter>

      <chapter xml:id="ch-locales">
        <title>Locales</title>
        
          <p>Computer settings change depending on language and location, and being unaware of this possibility can make certain data wrangling challenges difficult to overcome.</p>

          <p>The purpose of <em>locales</em> is to group together common settings that can affect:</p>

          <ol>
            <li><p>Month and day names, which are necessary for interpreting dates.</p></li>
            <li><p>The standard date format, also necessary for interpreting dates.</p></li>
            <li><p>The default time zone, essential for interpreting date-times.</p></li>
            <li><p>Character encoding, vital for reading non-ASCII characters. </p></li>
            <li><p>The symbols for decimals and number groupings, important for interpreting numerical values.</p></li>
          </ol>

          <p>In R, a <em>locale</em> refers to a suite of settings that dictate how the system should behave with respect to cultural conventions. These settings affect the way data is formatted and presented, encompassing details such as date formatting, currency symbols, decimal separators, and other related aspects.</p>

          <p>Locales in R affect several areas, including how character vectors are sorted, and date, number, and currency formatting. Additionally,  errors, warnings, and other messages might be translated into languages other than English based on the locale.</p>

        <section xml:id="sec-locales-in-r">
          <title>Locales in R</title>

          <p>To access the current locale settings in R, you can use the <c>Sys.getlocale()</c> function:</p>

          <sage language="r">
            <input>
Sys.getlocale()
            </input>
          </sage>

          <p>To set a specific locale, use the <c>Sys.setlocale()</c> function. For example, to set the locale to US English:</p>

          <sage language="r">
            <input>
Sys.setlocale("LC_ALL", "en_US.UTF-8")
            </input>
          </sage>

          <p>The exact string to use for setting the locale (like "en_US.UTF-8") can depend on your operating system and its configuration.</p>

          <p>The <c>LC_ALL</c> used in the above code refers to all locale categories. R, like many systems, breaks down the locale into categories, each responsible for different aspects listed below.</p>

          <p>- <c>LC_COLLATE</c>: for string collation - <c>LC_TIME</c>: date and time formatting - <c>LC_MONETARY</c>: currency formatting. - <c>LC_MESSAGES</c>: system message translations. - <c>LC_NUMERIC</c>: number formatting.</p>

          <p>You can set the locale for each category individually if you don't want to change everything with <c>LC_ALL</c>.</p>

          <p>We have shown tools to control locales. These settings are important because they affect how your data looks and behaves. However, not all of these settings are available on every computer; their availability depends on what kind of computer you have and how it's set up.</p>

          <p>Changing these settings, especially <c>LC_NUMERIC</c>, can lead to unexpected problems when you're working with numbers in R. For example, if you're used to using a period as a decimal point, but your locale uses a comma, this disparity can create issues when importing data.</p>

          <p>It is important to remember that these locale settings only last as long as one R session. If you change them while you're working, they will revert to the default settings when you close R and open it again.</p>

        </section>

        <section xml:id="sec-the-locale-function">
          <title>The `locale` function</title>

          <p>The <alert>readr</alert> package includes a <c>locale()</c> function that can be used to learn or change the current locale from within R:</p>

          <sage language="r">
            <input>
library(readr)
locale()
            </input>
          </sage>

          <sage language="r">
            <input>
#| echo: false
options(readr.show_col_types = FALSE)
            </input>
          </sage>

          <p>You can see all the locales available on your system by typing:</p>

          <sage language="r">
            <input>
#| eval: false
system("locale -a")
            </input>
          </sage>

          <p>Here is what you obtain if you change the dates locale to Spanish:</p>

          <sage language="r">
            <input>
locale(date_names = "es")
            </input>
          </sage>

        </section>

        <section xml:id="sec-example-wrangling-a-spanish-dataset">
          <title>Example: wrangling a Spanish dataset</title>

          <p>When reading the file:</p>

          <sage language="r">
            <input>
fn &lt;- file.path(system.file("extdata", package = "dslabs"), "calificaciones.csv")
            </input>
          </sage>

          <p>we note that it has an encoding different than UTF-8, the default. We can use <c>guess_encoding</c> to determine the correct one:</p>

          <sage language="r">
            <input>
guess_encoding(fn)$encoding[1]
            </input>
          </sage>

          <p>and used the <c>locale</c> function to change this and read in this encoding instead:</p>

          <sage language="r">
            <input>
#| eval: false
dat &lt;- read_csv(fn, locale = locale(encoding = "ISO-8859-1"))
            </input>
          </sage>

          <p>This file provides homework assignment scores for seven students. The columns represent the student name, their date of birth, the time they submitted their assignment, and the score they obtained, respectively. You can see the entire file using <c>read_lines</c>:</p>

          <sage language="r">
            <input>
read_lines(fn, locale = locale(encoding = "ISO-8859-1"))
            </input>
          </sage>

          <p>As an illustrative example, we will write code to compute the students age and check if they turned in their assignment by the deadline of September 21, 2023, before midnight.</p>

          <p>We can read in the file with correct encoding like this:</p>

          <sage language="r">
            <input>
dat &lt;- read_csv(fn, locale = locale(encoding = "ISO-8859-1"))
            </input>
          </sage>

          <p>However, notice that the last column, which is supposed to contain exam scores between 0 and 100, shows numbers larger than 800:</p>

          <sage language="r">
            <input>
dat$puntuacin
            </input>
          </sage>

          <p>This happens because the scores in the file use the European decimal point, which confuses <c>read_csv</c>.</p>

          <p>To address this issue, we can also change the encoding to use European decimals, which fixes the problem:</p>

          <sage language="r">
            <input>
dat &lt;- read_csv(fn, locale = locale(decimal_mark = ",",
                                    encoding = "ISO-8859-1"))
dat$puntuacin
            </input>
          </sage>

          <p>Now, to compute the student ages, let's try changing the submission times to date format:</p>

          <sage language="r">
            <input>
library(lubridate)
dmy(dat$f.n.)
            </input>
          </sage>

          <p>Nothing gets converted correctly. This is because the dates are in Spanish. We can change the locale to use Spanish as the language for dates:</p>

          <sage language="r">
            <input>
parse_date(dat$f.n., format = "%d de %B de %Y", locale = locale(date_names = "es"))
            </input>
          </sage>

          <p>We can also reread the file using the correct locales:</p>

          <sage language="r">
            <input>
dat &lt;- read_csv(fn, locale = locale(date_names = "es",
                                    date_format = "%d de %B de %Y",
                                    decimal_mark = ",",
                                    encoding = "ISO-8859-1"))
            </input>
          </sage>

          <p>Computing the students' ages is now straightforward:</p>

          <sage language="r">
            <input>
time_length(today() - dat$f.n., unit = "years") |&gt; floor()
            </input>
          </sage>

          <p>Finally, let's check which students turned in their homework past the deadline of September 22:</p>

          <sage language="r">
            <input>
dat$estampa &gt;= make_date(2023, 9, 22)
            </input>
          </sage>

          <p>We see that two students where late. However, with times we have to be particularly careful as some functions default to the UTC timezone:</p>

          <sage language="r">
            <input>
tz(dat$estampa)
            </input>
          </sage>

          <p>If we change to the timezone to Eastern Standard Time (EST), we see no one was late:</p>

          <sage language="r">
            <input>
with_tz(dat$estampa, tz =  "EST") &gt;= make_date(2023, 9, 22)
            </input>
          </sage>

        </section>

        <section xml:id="sec-locales-exercises">
          <title>Exercises</title>

          <ol>
            <li><p>Load the <alert>lubridate</alert> package and set the locale to French for this exercise. </p></li>
            <li><p>Create a numeric vector containing the following numbers: 12345.67, 9876.54, 3456.78, and 5432.10.</p></li>
            <li><p>Use the <c>format()</c> function to format the numeric vector as currency, displaying the values in Euros. Ensure that the decimal point is represented correctly according to the French locale. Print the formatted currency values.</p></li>
            <li><p>Create a date vector with three dates: July 14, 1789, January 1, 1803, and July 5, 1962. Use the <c>format()</c> function to format the date vector in the "dd Month yyyy" format, where "Month" should be displayed in the French language. Ensure that the month names are correctly translated according to the French locale. Print the formatted date values.</p></li>
            <li><p>Reset the locale to the default setting (e.g., "C" or "en_US.UTF-8") to revert to the standard formatting.</p></li>
            <li><p>Repeat steps 2-4 for the numeric vector, and steps 5-7 for the date vector to observe the standard formatting.</p></li>
          </ol>

        </section>
        
      </chapter>

      <chapter xml:id="ch-extracting-data-from-the-web">
        <title>Extracting data from the web</title>
        
          <p>In today's digital age, the internet serves as a treasure trove of data. This chapter describes approaches for retrieving this data and preparing for data analysis. We focus on two primary methodologies: scraping html and API integration. Scraping html allows us to programmatically navigate and extract data from web pages, transforming the unstructured content of the HTML pages into structured data ready for analysis. On the other hand, APIs provide a more direct and efficient and structured access to data provided by web services. This chapter aims to introduce the basics needed to starting leveraging the web's vast data resources.</p>

        <section xml:id="sec-scraping-html">
          <title>Scraping HTML</title>

          <p>The data we need to answer a question is not always in a spreadsheet ready for us to read. For example, the US murders dataset we used in the R Basics chapter originally comes from this Wikipedia page:</p>

          <sage language="r">
            <input>
url &lt;- paste0("https://en.wikipedia.org/w/index.php?title=",
              "Gun_violence_in_the_United_States_by_state",
              "&amp;direction=prev&amp;oldid=810166167")
            </input>
          </sage>

          <p>You can see the data table when you visit the webpage:</p>

          <figure>
            <image source="wrangling/img/murders-data-wiki-page.png"/>
          </figure>

          <p>(Web page courtesy of Wikipedia. CC-BY-SA-3.0 license. Screenshot of part of the page.)</p>

          <p><em>Web scraping</em>, or <em>web harvesting</em>, is the term we use to describe the process of extracting data from a website. The reason we can do this is because the information used by a browser to render webpages is received as a text file from a server. The text is code written in hyper text markup language (HTML). Every browser has a way to show the html source code for a page, each one different. On Chrome, you can use Control-U on a PC and command+alt+U on a Mac. You will see something like this:</p>

          <figure>
            <image source="wrangling/img/html-code.png"/>
          </figure>

          <subsection xml:id="subsec-html">
            <title>HTML</title>

            <p>Because this code is accessible, we can download the HTML file, import it into R, and then write programs to extract the information we need from the page. However, once we look at HTML code, this might seem like a daunting task. But we will show you some convenient tools to facilitate the process. To get an idea of how it works, here are a few lines of code from the Wikipedia page that provides the US murders data:</p>

            <sage language="r">
              <input>
&lt;table class="wikitable sortable"&gt;
&lt;tr&gt;
&lt;th&gt;State&lt;/th&gt;
&lt;th&gt;&lt;a href="/wiki/List_of_U.S._states_and_territories_by_population" 
title="List of U.S. states and territories by population"&gt;Population&lt;/a&gt;&lt;br /&gt;
&lt;small&gt;(total inhabitants)&lt;/small&gt;&lt;br /&gt;
&lt;small&gt;(2015)&lt;/small&gt; &lt;sup id="cite_ref-1" class="reference"&gt;
&lt;a href="#cite_note-1"&gt;[1]&lt;/a&gt;&lt;/sup&gt;&lt;/th&gt;
&lt;th&gt;Murders and Nonnegligent
&lt;p&gt;Manslaughter&lt;br /&gt;
&lt;small&gt;(total deaths)&lt;/small&gt;&lt;br /&gt;
&lt;small&gt;(2015)&lt;/small&gt; &lt;sup id="cite_ref-2" class="reference"&gt;
&lt;a href="#cite_note-2"&gt;[2]&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/th&gt;
&lt;th&gt;Murder and Nonnegligent
&lt;p&gt;Manslaughter Rate&lt;br /&gt;
&lt;small&gt;(per 100,000 inhabitants)&lt;/small&gt;&lt;br /&gt;
&lt;small&gt;(2015)&lt;/small&gt;&lt;/p&gt;
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="/wiki/Alabama" title="Alabama"&gt;Alabama&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;4,853,875&lt;/td&gt;
&lt;td&gt;348&lt;/td&gt;
&lt;td&gt;7.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href="/wiki/Alaska" title="Alaska"&gt;Alaska&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;737,709&lt;/td&gt;
&lt;td&gt;59&lt;/td&gt;
&lt;td&gt;8.0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
              </input>
            </sage>

            <p>You can actually see the data, except data values are surrounded by html code such as <c>&lt;td&gt;</c>. We can also see a pattern of how it is stored. If you know HTML, you can write programs that leverage knowledge of these patterns to extract what we want. We also take advantage of a language widely used to make webpages look "pretty" called Cascading Style Sheets (CSS). We say more about this in <xref ref="sec-css-selectors"/>.</p>

            <p>Although we provide tools that make it possible to scrape data without knowing HTML, it is useful to learn some HTML and CSS. Not only does this improve your scraping skills, but it might come in handy if you are creating a webpage to showcase your work. There are plenty of online courses and tutorials for learning these. Two examples are Codeacademy and W3schools.</p>

          </subsection>

          <subsection xml:id="subsec-the-rvest-package">
            <title>The rvest package</title>

            <p>The __tidyverse__ provides a web harvesting package called __rvest__. The first step using this package is to import the webpage into R. The package makes this quite simple:</p>

            <sage language="r">
              <input>
library(tidyverse)
library(rvest)
h &lt;- read_html(url)
              </input>
            </sage>

            <p>Note that the entire Murders in the US Wikipedia webpage is now contained in <c>h</c>. The class of this object is:</p>

            <sage language="r">
              <input>
class(h)
              </input>
            </sage>

            <p>The __rvest__ package is actually more general; it handles XML documents. XML is a general markup language (that's what the ML stands for) that can be used to represent any kind of data. HTML is a specific type of XML specifically developed for representing webpages. Here we focus on HTML documents.</p>

            <p>Now, how do we extract the table from the object <c>h</c>? If you were to print <c>h</c>,  we would see information about the object that is not very informative. We can see all the code that defines the downloaded webpage using the <c>html_text</c> function like this:</p>

            <sage language="r">
              <input>
html_text(h)
              </input>
            </sage>

            <p>We don't show the output here because it includes thousands of characters. But if we look at it, we can see the data we are after are stored in an HTML table: you can see this in this line of the HTML code above <c>&lt;table class="wikitable sortable"&gt;</c>. The different parts of an HTML document, often defined with a message in between  <c>&lt;</c> and <c>&gt;</c>  are referred to as <em>nodes</em>. The __rvest__ package includes functions to extract nodes of an HTML document: <c>html_nodes</c> extracts all nodes of different types and <c>html_node</c> extracts the first one. To extract the tables from the html code we use:</p>

            <sage language="r">
              <input>
tab &lt;- h |&gt; html_nodes("table")
              </input>
            </sage>

            <p>Now, instead of the entire webpage, we just have the html code for the tables in the page:</p>

            <sage language="r">
              <input>
tab
              </input>
            </sage>

            <p>The table we are interested is the first one:</p>

            <sage language="r">
              <input>
tab[[1]]
              </input>
            </sage>

            <p>This is clearly not a tidy dataset, not even a data frame. In the code above, you can definitely see a pattern and writing code to extract just the data is very doable. In fact, __rvest__ includes a function just for converting HTML tables into data frames:</p>

            <sage language="r">
              <input>
tab &lt;- tab[[1]] |&gt; html_table()
class(tab)
              </input>
            </sage>

            <p>We are now much closer to having a usable data table:</p>

            <sage language="r">
              <input>
tab &lt;- tab |&gt; setNames(c("state", "population", "total", "murder_rate")) 
head(tab)
              </input>
            </sage>

            <p>We still have some wrangling to do. For example, we need to remove the commas and turn characters into numbers. Before continuing with this, we will learn a more general approach to extracting information from web sites.</p>

          </subsection>

          <subsection xml:id="sec-css-selectors">
            <title>CSS selectors</title>

            <p>The default look of a webpage made with the most basic HTML is quite unattractive. The aesthetically pleasing pages we see today are made using CSS to define the look and style of webpages. The fact that all pages for a company have the same style usually results from their use of the same CSS file to define the style. The general way these CSS files work is by defining how each of the elements of a webpage will look. The title, headings, itemized lists, tables, and links, for example, each receive their own style including font, color, size, and distance from the margin. CSS does this by leveraging patterns used to define these elements, referred to as <em>selectors</em>. An example of such a pattern, which we used above, is <c>table</c>, but there are many, many more.</p>

            <p>If we want to grab data from a webpage and we happen to know a selector that is unique to the part of the page containing this data, we can use the <c>html_nodes</c> function. However, knowing which selector can be quite complicated. In fact, the complexity of webpages has been increasing as they become more sophisticated. For some of the more advanced ones, it seems almost impossible to find the nodes that define a particular piece of data. However, selector gadgets actually make this possible.</p>

            <p>SelectorGadget is piece of software that allows you to interactively determine what CSS selector you need to extract specific components from the webpage. If you plan on scraping data other than tables from html pages, we highly recommend you install it. A Chrome extension is available which permits you to turn on the gadget and then, as you click through the page, it highlights parts and shows you the selector you need to extract these parts. There are various demos of how to do this including __rvest__ author Hadley Wickham's vignette and other tutorials based on the vignette.</p>

          </subsection>

        </section>

        <section xml:id="sec-json">
          <title>JSON</title>

          <p>Sharing data on the internet has become more and more common. Unfortunately, providers use different formats, which makes it harder for data analysts to wrangle data into R. Yet there are some standards that are also becoming more common. Currently, a format that is widely being adopted is the JavaScript Object Notation or JSON. Because this format is very general, it is nothing like a spreadsheet. This JSON file looks more like the code you use to define a list. Here is an example of information stored in a JSON format:</p>

          <sage language="r">
            <input>
library(jsonlite)
example &lt;- data.frame(name = c("Miguel", "Sofia", "Aya", "Cheng"), 
                      student_id = 1:4, exam_1 = c(85, 94, 87, 90), exam_2 = c(86, 93, 88, 91))
json &lt;- toJSON(example, pretty = TRUE) 
json
            </input>
          </sage>

          <p>The file above actually represents a data frame. To read it, we can use the function <c>fromJSON</c> from the __jsonlite__ package. Note that JSON files are often made available via the internet. Several organizations provide a JSON API or a web service that you can connect directly to and obtain data. Here is an example providing information Nobel prize winners:</p>

          <sage language="r">
            <input>
library(jsonlite)
nobel &lt;- fromJSON("http://api.nobelprize.org/v1/prize.json")
            </input>
          </sage>

          <p>This downloads a list. The first argument, named "prizes" is a table with information about Nobel prize winners. Each row holds corresponds to a particular year and category. The "laureates" column holds a list with a data frame for each winner with columns for id, firstname, surname, and motivation.</p>

          <sage language="r">
            <input>
nobel$prizes |&gt;
  filter(category == "literature" &amp; year == "1971") |&gt; 
  pull(laureates) |&gt;
  first() |&gt;
  select(id, firstname, surname)
            </input>
          </sage>

          <p>You can learn much more by examining tutorials and help files from the __jsonlite__ package. This package is intended for relatively simple tasks such as converting data into tables. For more flexibility, we recommend the __rjson__ package.</p>

        </section>

        <section xml:id="sec-data-apis">
          <title>Data APIs</title>

          <p>An Application Programming Interface (API) is a set of rules and protocols that allows different software entities to communicate with each other. It defines methods and data formats that software components should use when requesting and exchanging information. APIs play a crucial role in enabling the integration that make today's software so interconnected and versatile.</p>

          <subsection xml:id="subsec-api-types-and-concepts">
            <title>API types and concepts</title>

            <p>There are several types of APIs. The main ones related to retrieving data are:</p>

            <p>* <alert>Web Services</alert> - Often built using protocols like HTTP/HTTPS. Commonly used to enable applications to communicate with each other over the web. For instance, a weather application for a smartphone may use a web API to request weather data from a remote server.</p>

            <p>* <alert>Database APIs</alert> - Enable communication between an application and a database, SQL-based calls for example.</p>

            <p>Some key concepts associated with APIs:</p>

            <p>- <alert>Endpoints</alert>: Specific functions available through the API. For web APIs, an endpoint is usually a specific URL where the API can be accessed.</p>

            <p>- <alert>Methods</alert>: Actions that can be performed. In web APIs, these often correspond to HTTP methods like GET, POST, PUT, or DELETE.</p>

            <p>- <alert>Requests and Responses</alert>: The act of asking the API to perform its function is a <em>request</em>. The data it returns is the <em>response</em>.</p>

            <p>- <alert>Rate Limits</alert>: Restrictions on how often you can call the API, often used to prevent abuse or overloading of the service.</p>

            <p>- <alert>Authentication and Authorization</alert>: Mechanisms to ensure that only approved users or applications can use the API. Common methods include <em>API keys</em>, <em>OAuth</em>, or <em>Jason Web Tokens</em> (JWT).</p>

            <p>- <alert>Data Formats</alert>: Many web APIs exchange data in a specific format, often JSON or CSV.</p>

            <p>Here now describe the <alert>httr2</alert> package that facilitates interacionts between R and HTTP web services.</p>

          </subsection>

          <subsection xml:id="subsec-the-httr2-package">
            <title>The httr2 package</title>

            <p>HTTP is the most widely used protocol for data sharing through the internet. The <alert>httr2</alert> package provides functions to work with HTTP requests. One of the core functions in this package is <c>request</c>, which is used to form request to send to web services. The <c>req_perform</c> function sends the request.</p>

            <p>This <c>request</c> function forms an HTTP GET request to the specified URL. Typically, HTTP GET requests are used to retrieve information from a server based on the provided URL.</p>

            <p>The function returns an object of class <c>response</c>. This object contains all the details of the server's response, including status code, headers, and content. You can then use other <alert>httr2</alert> functions to extract or interpret information from this response.</p>

            <p>Let's say you want to retrieve COVID-19 deaths by state from the CDC. By visiting their data catalog you can search for datasets and find that the data is provided through this API:</p>

            <sage language="r">
              <input>
url &lt;- "https://data.cdc.gov/resource/muzy-jte6.csv"
              </input>
            </sage>

            <p>We can then make create and perform a request like this:</p>

            <sage language="r">
              <input>
library(httr2)
response &lt;- request(url) |&gt; req_perform()
              </input>
            </sage>

            <p>We can see the results of the request by looking at the returned object.</p>

            <sage language="r">
              <input>
response
              </input>
            </sage>

            <p>To extract the body, which is where the data are, we can use <c>resp_body_string</c> and send the result, a comma delimited string, to <c>read_csv</c></p>

            <sage language="r">
              <input>
#| message: false
library(readr)
tab &lt;- response |&gt; resp_body_string() |&gt; read_csv()
              </input>
            </sage>

            <p>We note that the returned object is only <c>nrow(tab)</c> entries. API often limit how much you can download. The documentation for this API explains that we can change this limit through the <c>$limit</c> parameters. We can use the <c>req_url_query</c> to add this to our request:</p>

            <sage language="r">
              <input>
response &lt;- request(url) |&gt; 
  req_url_query(`$limit` = 100000) |&gt;
  req_perform() 
              </input>
            </sage>

            <p>The CDC service returns data in csv format but a more common format used by web services is JSON. The CDC also provides data in json format through a the url:</p>

            <sage language="r">
              <input>
url &lt;- "https://data.cdc.gov/resource/muzy-jte6.json"
              </input>
            </sage>

            <p>To extract the data table we use the <c>fromJSON</c> function from the <alert>jsonlite</alert> package.</p>

            <sage language="r">
              <input>
tab &lt;- request(url) |&gt; 
   req_perform() |&gt; 
   resp_body_string() |&gt; 
   fromJSON(flatten = TRUE)
              </input>
            </sage>

            <p>When working with APIs, it's essential to check the API's documentation for rate limits, required headers, or authentication methods. The <c>httr2</c> package provides tools to handle these requirements, such as setting headers or authentication parameters.</p>

          </subsection>

        </section>

        <section xml:id="sec-extracting-data-from-web-exercises">
          <title>Exercises</title>

          <ol>
            <li><p>Visit the following web page: <url href="https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm">https://web.archive.org/web/20181024132313/http://www.stevetheump.com/Payrolls.htm</url></p></li>
          </ol>

          <p>Notice there are several tables. Say we are interested in comparing the payrolls of teams across the years. The next few exercises take us through the steps needed to do this.</p>

          <p>Start by applying what you learned to read in the website into an object called <c>h</c>.</p>

          <ol>
            <li><p>Note that, although not very useful, we can actually see the content of the page by typing:</p></li>
          <sage language="r">
            <input>
html_text(h)
            </input>
          </sage>

          </ol>

          <p>The next step is to extract the tables. For this, we can use the <c>html_nodes</c> function. We learned that tables in html are associated with the <c>table</c> node.  Use the <c>html_nodes</c> function to extract all tables. Store it in an object <c>nodes</c>.</p>

          <ol>
            <li><p>The <c>html_nodes</c> function returns a list of objects of class <c>xml_node</c>. We can see the content of each one using, for example, the <c>html_text</c> function. You can see the content for an arbitrarily picked component like this:</p></li>
          <sage language="r">
            <input>
html_text(nodes[[8]])
            </input>
          </sage>

          </ol>

          <p>If the content of this object is an html table, we can use the <c>html_table</c> function to convert it to a data frame. Use the <c>html_table</c> function to convert the 8th entry of <c>nodes</c> into a table.</p>

          <ol>
            <li><p>Repeat the above for the first 4 components of <c>nodes</c>. Which of the following are payroll tables:</p></li>
          </ol>

          <p>a. All of them. b. 1 c. 2 d. 2-4</p>

          <ol>
            <li><p>Repeat the above for the first __last__ 3 components of <c>nodes</c>. Which of the following is true:</p></li>
          </ol>

          <p>a. The last entry in <c>nodes</c> shows the average across all teams through time, not payroll per team. b. All three are payroll per team tables. c. All three are like the first entry, not a payroll table. d. All of the above.</p>

          <ol>
            <li><p>We have learned that the first and last entries of <c>nodes</c> are not payroll tables. Redefine <c>nodes</c> so that these two are removed.</p></li>
            <li><p>We saw in the previous analysis that the first table node is not actually a table. This happens sometimes in html because tables are used to make text look a certain way, as opposed to storing numeric values. </p></li>
          </ol>

          <p>Remove the first component and then use <c>sapply</c> and <c>html_table</c> to convert each node in <c>nodes</c> into a table. Note that in this case, <c>sapply</c> will return a list of tables. You can also use <c>lapply</c> to assure that a list is applied.</p>

          <ol>
            <li><p>Look through the resulting tables. Are they all the same? Could we just join them with <c>bind_rows</c>? </p></li>
            <li><p>Create two tables, call them <c>tab_1</c> and <c>tab_2</c> using the 10th and 19th tables in <c>nodes</c>.</p></li>
            <li><p>Use a <c>full_join</c> function to combine these two tables. Before you do this you will have to fix the missing header problem. You will also need to make the names match.</p></li>
            <li><p>After joining the tables, you see several <c>NA</c>s. This is because some teams are in one table and not the other. Use the <c>anti_join</c> function to get a better idea of why this is happening.</p></li>
            <li><p>We see see that one of the problems is that Yankees are listed as both <em>N.Y. Yankees</em> and <em>NY Yankees</em>. In the next section, we will learn efficient approaches to fixing problems like this. Here we can do it "by hand" as follows:</p></li>
          <sage language="r">
            <input>
tab_1 &lt;- tab_1 |&gt;
  mutate(Team = ifelse(Team == "N.Y. Yankees", "NY Yankees", Team))
            </input>
          </sage>

          </ol>

          <p>Now join the tables and show only Oakland and the Yankees and the payroll columns.</p>

          <ol>
            <li><p>Advanced: extract the titles of the movies that won Best Picture from IMDB.</p></li>
          </ol>

        </section>
        
      </chapter>

      <chapter xml:id="ch-string-processing">
        <title>String processing</title>
        
          <p>One of the most common data wrangling challenges involves extracting numeric data contained in character strings and converting them into the numeric representations required to make plots, compute summaries, or fit models in R. Also common is processing unorganized text into meaningful variable names or categorical variables. Many of the string processing challenges a data scientist faces are unique and often unexpected. It is therefore quite ambitious to write a comprehensive section on this topic. Here we use a series of case studies that help us demonstrate how string processing is a necessary step for many data wrangling challenges. Specifically, we describe the process of converting the original, <em>raw</em> data from which we extracted the <c>murders</c>, <c>heights</c>, and <c>research_funding_rates</c> examples into the data frames we have studied in this book.</p>

          <p>By going over these case studies, we will cover some of the most common tasks in string processing including extracting numbers from strings, removing unwanted characters from text, finding and replacing characters, extracting specific parts of strings, converting free form text to more uniform formats, and splitting strings into multiple values.</p>

          <p>Base R includes functions to perform many of these tasks. The <alert>stringi</alert> package adds significant functionality over what is available in base R, especially for complex and diverse text processing needs. The <alert>stringr</alert> package provides consistent, simple, and user friendly wrappers around the <alert>stringi</alert> package. For example, in <alert>stringr</alert>, all the string processing functions start with <c>str_</c>. This means that if you type <c>str_</c> and hit tab, R will auto-complete and show all the available functions. As a result, we don't necessarily have to memorize all the function names. Another advantage is that in the functions in this package the string being processed is always the first argument, which means we can more easily use the pipe. Therefore, we will start by describing how to use the functions in the <alert>stringr</alert> package.</p>

          <p>Most of the examples will come from the second case study which deals with self-reported heights by students, and most of the chapter is dedicated to learning regular expressions (regex) and functions in the <alert>stringr</alert> package.</p>

        <section xml:id="sec-stringr">
          <title>The stringr package</title>

          <sage language="r">
            <input>
library(tidyverse)
library(stringr)
            </input>
          </sage>

          <p>In general, string processing tasks can be divided into <alert>detecting</alert>, <alert>locating</alert>, <alert>extracting</alert>, or <alert>replacing</alert> patterns in strings. We will see several examples. The table below includes the functions available to you in the <alert>stringr</alert> package. We split them by task. We also include the base R equivalent when available.</p>

          <p>All these functions take a character vector as first argument. Also, for each function, operations are vectorized: the operation gets applied to each string in the vector.</p>

          <p>Finally, we mention <em>groups</em> in this table. These will be explained in <xref ref="sec-groups"/>.</p>

          <p>| stringr           | Task       | Description                                                                                      | Base R                         | |--------------|--------------|-------------------------------|--------------| | <c>str_detect</c>      | Detect     | Is the pattern in the string?                                                                    | <c>grepl</c>                        | | <c>str_which</c>       | Detect     | Returns the index of entries that contain the pattern.                                           | <c>grep</c>                         | | <c>str_subset</c>      | Detect     | Returns the subset of strings that contain the pattern.                                          | <c>grep</c> with <c>value = TRUE</c>     | | <c>str_locate</c>      | Locate     | Returns positions of first occurrence of the pattern in a string.                                    | <c>regexpr</c>                      | | <c>str_locate_all</c>  | Locate     | Returns position of all occurrences of the pattern in a string.                                      | <c>gregexpr</c>                     | | <c>str_view</c>        | Locate     | Show the first part of the string that matches the pattern.                                          |                                | | <c>str_view_all</c>    | Locate     | Show all the parts of the string that match the pattern.                                      |                                | | <c>str_extract</c>     | Extract    | Extract the first part of the string that matches the pattern.                                   |                                | | <c>str_extract_all</c> | Extract    | Extract all parts of the string that match the pattern.                                          |                                | | <c>str_match</c>       | Extract    | Extract first part of the string that matches the pattern and the groups defined by the pattern. |                                | | <c>str_match_all</c>   | Extract    | Extract all parts of the string that match the pattern and the groups defined by the pattern.  |                                | | <c>str_sub</c>         | Extract    | Extract a substring.                                                                             | <c>substring</c>                    | | <c>str_split</c>       | Extract    | Split a string into a list with parts separated by a pattern.                                      | <c>strsplit</c>                     | | <c>str_split_fixed</c> | Extract    | Split a string into a matrix with a fixed number of parts separated by a pattern.                                    | <c>strsplit</c> with <c>fixed = TRUE</c> | | <c>str_count</c>       | Describe   | Count number of times a pattern appears in a string.                                             |                                | | <c>str_length</c>      | Describe   | Number of character in string.                                                                   | <c>nchar</c>                        | | <c>str_replace</c>     | Replace    | Replace first part of a string matching a pattern with another.                                  |                                | | <c>str_replace_all</c> | Replace    | Replace all parts of a string matching a pattern with another.                                   | <c>gsub</c>                         | | <c>str_to_upper</c>    | Replace    | Change all characters to upper case.                                                             | <c>toupper</c>                      | | <c>str_to_lower</c>    | Replace    | Change all characters to lower case.                                                             | <c>tolower</c>                      | | <c>str_to_title</c>    | Replace    | Change first character of each word to upper and rest to lower case.                                               |                                | | <c>str_replace_na</c>  | Replace    | Replace all <c>NA</c>s with a new value.                                                                |                                | | <c>str_trim</c>        | Replace    | Remove white space from start and end of string.                                                 |                                | | <c>str_c</c>           | Manipulate | Join multiple strings.                                                                           | <c>paste0</c>                       | | <c>str_conv</c>        | Manipulate | Change the encoding of the string.                                                               |                                | | <c>str_sort</c>        | Manipulate | Sort the vector in alphabetical order.                                                           | <c>sort</c>                         | | <c>str_order</c>       | Manipulate | Provide index needed to order the vector in alphabetical order.                                          | <c>order</c>                        | | <c>str_trunc</c>       | Manipulate | Truncate a string to a fixed size.                                                               |                                | | <c>str_pad</c>         | Manipulate | Add white space to string to make it a fixed size.                                               |                                | | <c>str_dup</c>         | Manipulate | Repeat a string.                                                                                 | <c>rep</c> then <c>paste</c>             | | <c>str_wrap</c>        | Manipulate | Wrap things into formatted paragraphs.                                                           |                                | | <c>str_interp</c>      | Manipulate | String interpolation.                                                                            | <c>sprintf</c>                      |</p>

        </section>

        <section xml:id="sec-case-study-1-self-reported-heights">
          <title>Case study 1: self-reported heights</title>

          <p>The <alert>dslabs</alert> package includes the raw data from which the heights dataset was obtained. You can load it like this:</p>

          <sage language="r">
            <input>
library(dslabs)
head(reported_heights)
            </input>
          </sage>

          <p>These heights were obtained using a web form in which students were asked to enter their heights. They could enter anything, but the instructions asked for <em>height in inches</em>, a number. We compiled <c>prettyNum(nrow(reported_heights), big.mark=",")</c> submissions, but unfortunately the column vector with the reported heights had several non-numeric entries and as a result became a character vector:</p>

          <sage language="r">
            <input>
class(reported_heights$height)
            </input>
          </sage>

          <p>If we try to parse it into numbers, we get a warning:</p>

          <sage language="r">
            <input>
x &lt;- as.numeric(reported_heights$height)
            </input>
          </sage>

          <p>Although most values appear to be height in inches as requested we do end up with many <c>NA</c>s:</p>

          <sage language="r">
            <input>
sum(is.na(x))
            </input>
          </sage>

          <p>Here are some of the entries that are not successfully converted:</p>

          <sage language="r">
            <input>
reported_heights |&gt; 
  mutate(new_height = as.numeric(height)) |&gt;
  filter(is.na(new_height)) |&gt; 
  head(n = 10)
            </input>
          </sage>

          <p>We immediately see what is happening. Some of the students did not report their heights in inches as requested. We could discard these data and continue. However, many of the entries follow patterns that, in principle, we can easily convert to inches. For example, in the output above, we see various cases that use the format <c>x'y"</c> or <c>x'y''</c> with <c>x</c> and <c>y</c> representing feet and inches, respectively. Each one of these cases can be read and converted to inches by a human, for example <c>5'4"</c> is <c>5*12 + 4 = 64</c>. So we could fix all the problematic entries <em>by hand</em>. However, humans are prone to making mistakes, so an automated approach is preferable. Also, because we plan on continuing to collect data, it will be convenient to write code that automatically corrects entries entered in error.</p>

          <p>A first step in this type of task is to survey the problematic entries and try to define specific patterns followed by a large groups of entries. The larger these groups, the more entries we can fix with a single programmatic approach. We want to find patterns that can be accurately described with a rule, such as "a digit, followed by a feet symbol, followed by one or two digits, followed by an inches symbol".</p>

          <p>To look for such patterns, it helps to remove the entries that are consistent with being in inches and to view only the problematic entries. We thus write a function to automatically do this. We keep entries that either result in <c>NA</c>s when applying <c>as.numeric</c> or are outside a range of plausible heights. We permit a range that covers about 99.9999% of the adult population. We also use <c>suppressWarnings</c> to avoid the warning message we know <c>as.numeric</c> will gives us.</p>

          <sage language="r">
            <input>
alpha &lt;- 1 / 10^6
qnorm(1 - alpha / 2, 69.1, 2.9)
qnorm(alpha / 2, 63.7, 2.7)
            </input>
          </sage>

          <p>We apply this function and find the number of problematic entries:</p>

          <sage language="r">
            <input>
problems &lt;- reported_heights |&gt; 
  mutate(inches = suppressWarnings(as.numeric(height))) |&gt;
  filter(is.na(inches) | inches &lt; 50 | inches &gt; 84) |&gt;
  pull(height)
length(problems)
            </input>
          </sage>

          <p>We can now view all the cases by simply printing them. If we do, we see that three patterns can be used to define three large groups within these exceptions.</p>

          <ol>
            <li><p>A pattern of the form <c>x'y</c> or <c>x' y''</c> or <c>x'y"</c> with <c>x</c> and <c>y</c></p></li>
          </ol>

          <p>representing feet and inches, respectively. Here are ten examples:</p>

          <sage language="r">
            <input>
pattern &lt;- "^\\d\\s*'\\s*\\d{1,2}\\.*\\d*'*\"*$"
str_subset(problems, pattern) |&gt; head(n = 10) |&gt; cat()
            </input>
          </sage>

          <ol>
            <li><p>A pattern of the form <c>x.y</c> or <c>x,y</c> with <c>x</c> feet and <c>y</c> inches.</p></li>
          </ol>

          <p>Here are ten examples:</p>

          <sage language="r">
            <input>
pattern &lt;- "^[4-6]\\s*[\\.|,]\\s*([0-9]|10|11)$"
str_subset(problems, pattern) |&gt; head(n = 10) |&gt; cat()
            </input>
          </sage>

          <ol>
            <li><p>Entries that were reported in centimeters rather than inches. Here</p></li>
          </ol>

          <p>are ten examples:</p>

          <sage language="r">
            <input>
ind &lt;- which(between(suppressWarnings(as.numeric(problems))/2.54, 54, 81) )
ind &lt;- ind[!is.na(ind)]
problems[ind] |&gt; head(n = 10) |&gt; cat()
            </input>
          </sage>

          <p>Once we see these large groups following specific patterns, we can develop a plan of attack.</p>

          <ol>
            <li><p>Convert entries fitting the first two patterns into one standardized</p></li>
          </ol>

          <p>one.</p>

          <ol>
            <li><p>Leverage the standardization to extract the feet and inches and</p></li>
          </ol>

          <p>convert to inches.</p>

          <ol>
            <li><p>Define a procedure for identifying entries that are in centimeters</p></li>
          </ol>

          <p>and convert them to inches.</p>

          <ol>
            <li><p>Check again to see what entries were not fixed and see if we can</p></li>
          </ol>

          <p>tweak our approach to be more comprehensive.</p>

          <p>At the end, we hope to have a script that makes web-based data collection methods robust to the most common user mistakes.</p>

          <p>Remember that there is rarely just one way to perform these tasks. Here we pick one that helps us teach several useful techniques. But surely there is a more efficient way of performing the task.</p>

          <p>To achieve our goal, we will use a technique that enables us to accurately detect patterns and extract the parts we want: <em>regular expressions</em> (regex). But first, we quickly describe how to <em>escape</em> the function of certain characters so that they can be included in strings.</p>

        </section>

        <section xml:id="sec-escaping">
          <title>Escaping</title>

          <p>To define strings in R, we can use either double quotes or single quotes:</p>

          <sage language="r">
            <input>
s &lt;- "Hello!"
s &lt;- 'Hello!' 
            </input>
          </sage>

          <p>Make sure you choose the correct single quote, as opposed to the back quote `<c> </c> ``.</p>

          <p>Now, what happens if the string we want to define includes double quotes? For example, if we want to write 10 inches like this <c>10"</c>? In this case you can't use:</p>

          <sage language="r">
            <input>
s &lt;- "10""
            </input>
          </sage>

          <p>because this is just the string <c>10</c> followed by a double quote. If you type this into R, you get an error because you failed to close the double quote. To avoid this, we can use the single quotes:</p>

          <sage language="r">
            <input>
s &lt;- '10"'
            </input>
          </sage>

          <p>If we print out <c>s</c> we see that the double quotes are <em>escaped</em> with the backslash <c>\</c>.</p>

          <sage language="r">
            <input>
s
            </input>
          </sage>

          <p>In fact, escaping with the backslash provides a way to define the string while still using the double quotes to define strings:</p>

          <sage language="r">
            <input>
s &lt;- "10\""
            </input>
          </sage>

          <p>In R, the function <c>cat</c> lets us see what the string actually looks like:</p>

          <sage language="r">
            <input>
cat(s)
            </input>
          </sage>

          <p>Now, what if we want our string to be 5 feet written like this <c>5'</c>? In this case, we can use the double quotes or escape the single quote</p>

          <sage language="r">
            <input>
s &lt;- "5'"
s &lt;- '5\''
            </input>
          </sage>

          <p>So we've learned how to write 5 feet and 10 inches separately, but what if we want to write them together to represent <em>5 feet and 10 inches</em> like this <c>5'10"</c>? In this case, neither the single nor double quotes will work since <c>'5'10"'</c> closes the string after 5 and this <c>"5'10""</c> closes the string after 10. Keep in mind that if we type one of the above code snippets into R, it will get stuck waiting for you to close the open quote and you will have to exit the execution with the <em>esc</em> button.</p>

          <p>To achieve the desired result we need to escape both quotes with the backslash <c>\</c>. You can escape either character that can be confused with a closing quote. These are the two options:</p>

          <sage language="r">
            <input>
s &lt;- '5\'10"'
s &lt;- "5'10\""
            </input>
          </sage>

          <p>Escaping characters is something we often have to use when processing strings. Another characters that often needs escaping is the backslash character itself. We can do this with <c>\\</c>. When using regular expression, the topic of the next section, we often have to escape the <em>special characters</em> used in this approach.</p>

        </section>

        <section xml:id="sec-regex">
          <title>Regular expressions</title>

          <p>A regular expression (regex) is a way to describe specific patterns of characters of text. They can be used to determine if a given string matches the pattern. A set of rules has been defined to do this efficiently and precisely and here we show some examples. We can learn more about these rules by reading a detailed tutorials . The RStudio cheat sheet for __stringr__ and regular expression is also very useful.</p>

          <p>The patterns supplied to the <alert>stringr</alert> functions can be a regex rather than a standard string. We will learn how this works through a series of examples.</p>

          <p>Throughout this section you will see that we create strings to test out our regex. To do this, we define patterns that we know should match and also patterns that we know should not. We will call them <c>yes</c> and <c>no</c>, respectively. This permits us to check for the two types of errors: failing to match and incorrectly matching.</p>

          <subsection xml:id="subsec-strings-are-a-regex">
            <title>Strings are a regex</title>

            <p>Technically any string is a regex, perhaps the simplest example is a single character. So the comma <c>,</c> used in the next code example is a simple example of searching with regex.</p>

            <sage language="r">
              <input>
pattern &lt;- ","
str_detect(c("1", "10", "100", "1,000", "10,000"), pattern) 
              </input>
            </sage>

            <p>Above, we noted that an entry included a <c>cm</c>. This is also a simple example of a regex. We can show all the entries that used <c>cm</c> like this:</p>

            <sage language="r">
              <input>
str_subset(reported_heights$height, "cm")
              </input>
            </sage>

          </subsection>

          <subsection xml:id="subsec-special-characters">
            <title>Special characters</title>

            <p>Now let's consider a slightly more complicated example. Which of the following strings contain the pattern <c>cm</c> or <c>inches</c>?</p>

            <sage language="r">
              <input>
yes &lt;- c("180 cm", "70 inches")
no &lt;- c("180", "70''")
s &lt;- c(yes, no)
              </input>
            </sage>

            <p>We can do this with two searches:</p>

            <sage language="r">
              <input>
str_detect(s, "cm") | str_detect(s, "inches")
              </input>
            </sage>

            <p>However, we don't need to do this. The main feature that distinguishes the regex <em>language</em> from plain strings is that we can use special characters. These are characters with a meaning. We start by introducing <c>|</c> which means <em>or</em>. So if we want to know if either <c>cm</c> or <c>inches</c> appears in the strings, we can use the regex <c>cm|inches</c>:</p>

            <sage language="r">
              <input>
str_detect(s, "cm|inches")
              </input>
            </sage>

            <p>and obtain the correct answer.</p>

            <p>Another special character that will be useful for identifying feet and inches values is <c>\d</c> which means any digit: 0, 1, 2, 3, 4, 5, 6, 7, 8,</p>

            <ol>
              <li><p>The backslash is used to distinguish it from the character <c>d</c>. In R,</p></li>
            </ol>

            <p>we have to <em>escape</em> the backslash <c>\</c> so we actually have to use <c>\\d</c> to represent digits. Here is an example:</p>

            <sage language="r">
              <input>
yes &lt;- c("5", "6", "5'10", "5 feet", "4'11")
no &lt;- c("", ".", "Five", "six")
s &lt;- c(yes, no)
pattern &lt;- "\\d"
str_detect(s, pattern)
              </input>
            </sage>

            <p>We take this opportunity to introduce the <c>str_view</c> function, which is helpful for troubleshooting as it shows us all matches for each string that has matches. Each match is surrounded by the characters <c>&lt;</c> and <c>&gt;</c>. Below, we see that <c>5</c> has one match and <c>5'10</c> has three matches.</p>

            <sage language="r">
              <input>
str_view(s, pattern)
              </input>
            </sage>

            <figure>
              <image source="wrangling/img/str_view-1.png"/>
            </figure>

            <p>To view all strings, even if there wasn't a match, we can use the <c>match = NA</c> parameter.</p>

            <sage language="r">
              <input>
str_view(s, pattern, match = NA)
              </input>
            </sage>

            <figure>
              <image source="wrangling/img/str_view-2.png"/>
            </figure>

            <p>Another useful special character is <c>\w</c> which stands for <em>word character</em> and it matches any letter, number, or underscore.</p>

            <p>There are many other special characters. We will learn some others below, but you can see most or all of them in the cheat sheet mentioned earlier.</p>

          </subsection>

          <subsection xml:id="subsec-character-classes">
            <title>Character classes</title>

            <p>Character classes are used to define a series of characters that can be matched. We define character classes with square brackets <c>[]</c>. So, for example, if we want the pattern to match only if we have a <c>5</c> or a <c>6</c>, we use the regex <c>[56]</c>:</p>

            <sage language="r">
              <input>
str_view(s, "[56]", match = NA)
              </input>
            </sage>

            <figure>
              <image source="wrangling/img/str_view-3.png"/>
            </figure>

            <p>Suppose we want to match values between 4 and 7. A common way to define character classes is with ranges. So, for example, <c>[0-9]</c> is equivalent to <c>\\d</c>. The pattern we want is therefore <c>[4-7]</c>.</p>

            <sage language="r">
              <input>
yes &lt;- as.character(4:7)
no &lt;- as.character(1:3)
s &lt;- c(yes, no)
str_detect(s, "[4-7]")
              </input>
            </sage>

            <p>However, it is important to know that in regex everything is a character; there are no numbers. So <c>4</c> is the character <c>4</c> not the number four. Notice, for example, that <c>[1-20]</c> does <alert>not</alert> mean 1 through 20, it means the characters 1 through 2 or the character 0. So <c>[1-20]</c> simply means the character class composed of 0, 1, and 2.</p>

            <p>Keep in mind that characters do have an order and the digits do follow the numeric order. So <c>0</c> comes before <c>1</c> which comes before <c>2</c> and so on. For the same reason, we can define lower case letters as <c>[a-z]</c>, upper case letters as <c>[A-Z]</c>, and <c>[a-zA-z]</c> as both.</p>

            <p>Notice that <c>\w</c> is equivalent to <c>[a-zA-Z0-9_]</c>.</p>

          </subsection>

          <subsection xml:id="subsec-anchors">
            <title>Anchors</title>

            <p>What if we want a match when we have exactly 1 digit? This will be useful in our case study since feet are never more than 1 digit so a restriction will help us. One way to do this with regex is by using <em>anchors</em>, which let us define patterns that must start or end at a specific place. The two most common anchors are <c>^</c> and <c>$</c> which represent the beginning and end of a string, respectively. So the pattern <c>^\\d$</c> is read as "start of the string followed by one digit followed by end of string".</p>

            <p>This pattern now only detects the strings with exactly one digit:</p>

            <sage language="r">
              <input>
pattern &lt;- "^\\d$"
yes &lt;- c("1", "5", "9")
no &lt;- c("12", "123", " 1", "a4", "b")
s &lt;- c(yes, no)
str_view(s, pattern, match = NA)
              </input>
            </sage>

            <figure>
              <image source="wrangling/img/str_view-4.png"/>
            </figure>

            <p>The <c> 1</c> does not match because it does not start with the digit but rather with a space, which is not easy to see.</p>

          </subsection>

          <subsection xml:id="subsec-bounded-quantifiers">
            <title>Bounded quantifiers</title>

            <p>For the inches part, we can have one or two digits. This can be specified in regex with <em>quantifiers</em>. This is done by following the pattern with curly brackets containing the number of times the previous entry can be repeated. We call the <em>bounded</em> because the numbers in the quantifier are limited by the numbers in the curly brackets. Later we learn about <em>unbounded quantifiers</em>.</p>

            <p>We use an example to illustrate. The pattern for one or two digits is:</p>

            <sage language="r">
              <input>
pattern &lt;- "^\\d{1,2}$"
yes &lt;- c("1", "5", "9", "12")
no &lt;- c("123", "a4", "b")
str_view(c(yes, no), pattern, match = NA)
              </input>
            </sage>

            <figure>
              <image source="wrangling/img/str_view-5.png"/>
            </figure>

            <p>In this case, <c>123</c> does <alert>not</alert> match, but <c>12</c> does. To look for our feet and inches pattern, we can add the symbols for feet <c>'</c> and inches <c>"</c> after the digits.</p>

            <p>With what we have learned, we can now construct an example for the pattern <c>x'y"</c> with <c>x</c> feet and <c>y</c> inches.</p>

            <sage language="r">
              <input>
pattern &lt;- "^[4-7]'\\d{1,2}\"$"
              </input>
            </sage>

            <p>The pattern is now getting complex, but you can look at it carefully and break it down:</p>

            <p>-   <c>^</c> = start of the string -   <c>[4-7]</c> = one digit, either 4,5,6 or 7 -   <c>'</c> = feet symbol -   <c>\\d{1,2}</c> = one or two digits -   <c>\"</c> = inches symbol -   <c>$</c> = end of the string</p>

            <p>Let's test it out:</p>

            <sage language="r">
              <input>
yes &lt;- c("5'7\"", "6'2\"",  "5'12\"")
no &lt;- c("6,2\"", "6.2\"","I am 5'11\"", "3'2\"", "64")
str_detect(yes, pattern)
str_detect(no, pattern)
              </input>
            </sage>

            <p>For now, we are permitting the inches to be 12 or larger. We will add a restriction later as the regex for this is a bit more complex than we are ready to show.</p>

          </subsection>

          <subsection xml:id="subsec-white-space">
            <title>White space</title>

            <p>Another problem we have is spaces. For example, our pattern does not match <c>5' 4"</c> because there is a space between <c>'</c> and <c>4</c> which our pattern does not permit. Spaces are characters and R does not ignore them:</p>

            <sage language="r">
              <input>
identical("Hi", "Hi ")
              </input>
            </sage>

            <p>In regex, <c>\s</c> represents white space. To find patterns like <c>5' 4</c>, we can change our pattern to:</p>

            <sage language="r">
              <input>
pattern_2 &lt;- "^[4-7]'\\s\\d{1,2}\"$"
str_subset(problems, pattern_2)
              </input>
            </sage>

            <p>However, this will not match the patterns with no space. So do we need more than one regex pattern? It turns out we can use a quantifier for this as well.</p>

          </subsection>

          <subsection xml:id="subsec-unbounded-quantifiers">
            <title>Unbounded quantifiers: `*`, `?`, `+`</title>

            <p>We want the pattern to permit spaces but not require them. Even if there are several spaces, like in this example <c>5'   4</c>, we still want it to match. There is a quantifier for exactly this purpose. In regex, the character <c>*</c> means zero or more instances of the previous character. Here is an example:</p>

            <sage language="r">
              <input>
yes &lt;- c("AB", "A1B", "A11B", "A111B", "A1111B")
no &lt;- c("A2B", "A21B")
str_detect(yes, "A1*B")
str_detect(no, "A1*B")
              </input>
            </sage>

            <p>The above matches the first string which has zero 1s and all the strings with one or more 1s. We can then improve our pattern by adding the <c>*</c> after the space character <c>\s</c>.</p>

            <p>There are two other similar quantifiers. For none or once, we can use <c>?</c>, and for one or more, we can use <c>+</c>. You can see how they differ with this example:</p>

            <sage language="r">
              <input>
data.frame(string = c("AB", "A1B", "A11B", "A111B", "A1111B"),
           none_or_more = str_detect(yes, "A1*B"),
           nore_or_once = str_detect(yes, "A1?B"),
           once_or_more = str_detect(yes, "A1+B"))
              </input>
            </sage>

            <p>We will actually use all three in our reported heights example, but we will see these in a later section.</p>

          </subsection>

          <subsection xml:id="subsec-not">
            <title>Not</title>

            <p>To specify patterns that we do <alert>not</alert> want to detect, we can use the <c>^</c> symbol but only <alert>inside</alert> square brackets. Remember that outside the square bracket <c>^</c> means the start of the string. So, for example, if we want to detect digits that are preceded by anything except a letter we can do the following:</p>

            <sage language="r">
              <input>
pattern &lt;- "[^a-zA-Z]\\d"
yes &lt;- c(".3", "+2", "-0","*4")
no &lt;- c("A3", "B2", "C0", "E4")
str_detect(yes, pattern)
str_detect(no, pattern)
              </input>
            </sage>

            <p>Another way to generate a pattern that searches for <em>everything except</em> is to use the upper case of the special character. For example <c>\\D</c> means anything other than a digit, <c>\\S</c> means anything except a space, and so on.</p>

          </subsection>

          <subsection xml:id="sec-groups">
            <title>Groups</title>

            <p><em>Groups</em> are a powerful aspect of regex that permits the extraction of values. Groups are defined using parentheses. They don't affect the pattern matching per se. Instead, it permits tools to identify specific parts of the pattern so we can extract them.</p>

            <p>We want to change heights written like <c>5.6</c> to <c>5'6</c>.</p>

            <p>To avoid changing patterns such as <c>70.2</c>, we will require that the first digit be between 4 and 7 <c>[4-7]</c> and that the second be none or more digits <c>\\d*</c>. Let's start by defining a simple pattern that matches this:</p>

            <sage language="r">
              <input>
pattern_without_groups &lt;- "^[4-7],\\d*$"
              </input>
            </sage>

            <p>We want to extract the digits so we can then form the new version using a period. These are our two groups, so we encapsulate them with parentheses:</p>

            <sage language="r">
              <input>
pattern_with_groups &lt;-  "^([4-7]),(\\d*)$"
              </input>
            </sage>

            <p>We encapsulate the part of the pattern that matches the parts we want to keep for later use. Adding groups does not affect the detection, since it only signals that we want to save what is captured by the groups. Note that both patterns return the same result when using <c>str_detect</c>:</p>

            <sage language="r">
              <input>
yes &lt;- c("5,9", "5,11", "6,", "6,1")
no &lt;- c("5'9", ",", "2,8", "6.1.1")
s &lt;- c(yes, no)
str_detect(s, pattern_without_groups)
str_detect(s, pattern_with_groups)
              </input>
            </sage>

            <p>Once we define groups, we can use the function <c>str_match</c> to extract the values these groups define:</p>

            <sage language="r">
              <input>
str_match(s, pattern_with_groups)
              </input>
            </sage>

            <p>Notice that the second and third columns contain feet and inches, respectively. The first column is the part of the string matching the pattern. If no match occurred, we see an <c>NA</c>.</p>

            <p>Now we can understand the difference between the functions <c>str_extract</c> and <c>str_match</c>. <c>str_extract</c> extracts only strings that match a pattern, not the values defined by groups:</p>

            <sage language="r">
              <input>
str_extract(s, pattern_with_groups)
              </input>
            </sage>

          </subsection>

          <subsection xml:id="subsec-search-and-replace">
            <title>Search and replace</title>

            <p>Earlier we defined the object <c>problems</c> containing the strings that do not appear to be in inches. We can see that not too many of our problematic strings match the pattern:</p>

            <sage language="r">
              <input>
pattern &lt;- "^[4-7]'\\d{1,2}\"$"
sum(str_detect(problems, pattern))
              </input>
            </sage>

            <p>To see why this is, we show some examples that expose why we don't have more matches:</p>

            <sage language="r">
              <input>
problems[c(2, 10, 11, 12, 15)] |&gt; str_view(pattern)
              </input>
            </sage>

            <figure>
              <image source="wrangling/img/str_view-6.png"/>
            </figure>

            <p>An initial problem we see immediately is that some students wrote out the words "feet" and "inches". We can see the entries that did this with the <c>str_subset</c> function:</p>

            <sage language="r">
              <input>
str_subset(problems, "inches")
              </input>
            </sage>

            <p>We also see that some entries used two single quotes <c>''</c> instead of a double quote <c>"</c>.</p>

            <sage language="r">
              <input>
str_subset(problems, "''")
              </input>
            </sage>

            <p>To correct this, we can replace the different ways of representing inches and feet with a uniform symbol. We will use <c>'</c> for feet, whereas for inches we will simply not use a symbol since some entries were of the form <c>x'y</c>. Now, if we no longer use the inches symbol, we have to change our pattern accordingly:</p>

            <sage language="r">
              <input>
pattern &lt;- "^[4-7]'\\d{1,2}$"
              </input>
            </sage>

            <p>If we do this replacement before the matching, we get many more matches:</p>

            <sage language="r">
              <input>
problems |&gt; 
  str_replace("feet|ft|foot", "'") |&gt; # replace feet, ft, foot with ' 
  str_replace("inches|in|''|\"", "") |&gt; # remove all inches symbols
  str_detect(pattern) |&gt; 
  sum()
              </input>
            </sage>

            <p>However, we still have many cases to go.</p>

            <p>Note that in the code above, we leveraged the <alert>stringr</alert> consistency and used the pipe.</p>

            <p>For now, we improve our pattern by adding <c>\\s*</c> in front of and after the feet symbol <c>'</c> to permit space between the feet symbol and the numbers. Now we match a few more entries:</p>

            <sage language="r">
              <input>
pattern &lt;- "^[4-7]\\s*'\\s*\\d{1,2}$"
problems |&gt; 
  str_replace("feet|ft|foot", "'") |&gt; # replace feet, ft, foot with ' 
  str_replace("inches|in|''|\"", "") |&gt; # remove all inches symbols
  str_detect(pattern) |&gt; 
  sum()
              </input>
            </sage>

            <p>We might be tempted to avoid doing this by removing all the spaces with <c>str_replace_all</c>. However, when doing such an operation we need to make sure that it does not have unintended effects. In our reported heights examples, this will be a problem because some entries are of the form <c>x y</c> with space separating the feet from the inches. If we remove all spaces, we will incorrectly turn <c>x y</c> into <c>xy</c> which implies that a <c>6 1</c> would become <c>61</c> inches instead of <c>73</c> inches.</p>

            <p>The second large type of problematic entries were of the form <c>x.y</c>, <c>x,y</c> and <c>x y</c>. We want to change all these to our common format <c>x'y</c>. But we can't just do a search and replace because we would change values such as <c>70.5</c> into <c>70'5</c>. Our strategy will therefore be to search for a very specific pattern that assures us feet and inches are being provided and then, for those that match, replace appropriately.</p>

          </subsection>

          <subsection xml:id="subsec-search-and-replace-using-groups">
            <title>Search and replace using groups</title>

            <p>Another powerful aspect of groups is that you can refer to the extracted values in a regex when searching and replacing.</p>

            <p>The regex special character for the <c>i</c>-th group is <c>\\i</c>. So <c>\\1</c> is the value extracted from the first group, <c>\\2</c> the value from the second and so on. As a simple example, note that the following code will replace a comma with period, but only if it is after a digit between 4 and 7, and followed by zero or more digits:</p>

            <sage language="r">
              <input>
pattern_with_groups &lt;-  "^([4-7]),(\\d*)$"
yes &lt;- c("5,9", "5,11", "6,", "6,1")
no &lt;- c("5'9", ",", "2,8", "6.1.1")
s &lt;- c(yes, no)
str_replace(s, pattern_with_groups, "\\1'\\2")
              </input>
            </sage>

            <p>We can use this to convert cases in our reported heights.</p>

            <p>We are now ready to define a pattern that helps us convert all the <c>x.y</c>, <c>x,y</c> and <c>x y</c> to our preferred format. We need to adapt <c>pattern_with_groups</c> to be a bit more flexible and capture all the cases.</p>

            <sage language="r">
              <input>
pattern_with_groups &lt;- "^([4-7])\\s*[,\\.\\s+]\\s*(\\d*)$"
              </input>
            </sage>

            <p>Let's break this one down:</p>

            <p>-   <c>^</c> = start of the string -   <c>[4-7]</c> = one digit representing feet, either 4, 5, 6, or 7 -   <c>\\s*</c> = none or more white space -   <c>[,\\.\\s+]</c> = feet and inches are separated by either <c>,</c>, <c>.</c> or at least one space -   <c>\\s*</c> = none or more white space -   <c>\\d*</c> = none or more digits representing inches -   <c>$</c> = end of the string</p>

            <p>We can see that it appears to be working:</p>

            <sage language="r">
              <input>
str_subset(problems, pattern_with_groups) |&gt; head()
              </input>
            </sage>

            <p>and will be able to perform the search and replace:</p>

            <sage language="r">
              <input>
str_subset(problems, pattern_with_groups) |&gt; 
  str_replace(pattern_with_groups, "\\1'\\2") |&gt; head()
              </input>
            </sage>

            <p>Again, we will deal with the inches-larger-than-twelve challenge later.</p>

          </subsection>

          <subsection xml:id="subsec-lookarounds">
            <title>Lookarounds</title>

            <p>Lookarounds provide a way to ask for one or more conditions to be satisfied without moving the search forward or matching it. For example, you might want to check for multiple conditions and if they are matched, then return the pattern or part of the pattern that matched.</p>

            <p>There are four types of lookarounds: lookahead <c>(?=pattern)</c>, lookbehind <c>(?&lt;=pattern)</c>, negative lookahead <c>(?!pattern)</c>, and negative lookbehind <c>(?&lt;!pattern)</c>.</p>

            <p>The conventional example checking password that must satisfy several conditions such as 1) 8-16 word characters, 2) starts with a letter, and 3) has at least one digit. You can concatenate lookarounds to check for multiple conditions. For our example we can write</p>

            <sage language="r">
              <input>
pattern &lt;- "(?=\\w{8,16})(?=^[a-z|A-Z].*)(?=.*\\d+.*)"
              </input>
            </sage>

            <p>A simpler example is changing all <c>superman</c> to <c>supergirl</c> without changing all the men to girl. We could use a lookaround like this:</p>

            <sage language="r">
              <input>
s &lt;- "Superman saved a man. The man thanked superman."
str_replace_all(s, "(?&lt;=[Ss]uper)man", "girl")
              </input>
            </sage>

          </subsection>

          <subsection xml:id="sec-separate_regex">
            <title>Separating variables</title>

            <p>In <xref ref="sec-separate"/> we introduced functions that can split columns into new ones. The <c>separate_wider_regex</c> uses regex instead of delimiters to separate variables in data frames. It uses an approach similar to regex groups and turns each of groups into a new column.</p>

            <p>Suppose we have data frame like this:</p>

            <sage language="r">
              <input>
tab &lt;- data.frame(x = c("5'10", "6' 1", "5 ' 9", "5'11\""))
              </input>
            </sage>

            <p>Note that using <c>separate_wider_delim</c> won't work here because the delimiter can varies across entries. With <c>separate_wider_regex</c> we can define flexible patterns that are matched to define each column.</p>

            <sage language="r">
              <input>
patterns &lt;- c(feet = "\\d", "\\s*'\\s*", inches = "\\d{1,2}", ".*")
tab |&gt; separate_wider_regex(x, patterns = patterns)
              </input>
            </sage>

            <p>By not naming the second and fourth entries of <c>patterns</c> we tell the function not to keep the values that match that pattern.</p>

          </subsection>

        </section>

        <section xml:id="sec-trimming">
          <title>Trimming</title>

          <p>In general, spaces at the start or end of the string are uninformative. These can be particularly deceptive because sometimes they can be hard to see:</p>

          <sage language="r">
            <input>
s &lt;- "Hi "
cat(s)
identical(s, "Hi")
            </input>
          </sage>

          <p>This is a general enough problem that there is a function dedicated to removing them: <c>str_trim</c>.</p>

          <sage language="r">
            <input>
str_trim("5 ' 9 ")
            </input>
          </sage>

        </section>

        <section xml:id="sec-case-conversion">
          <title>Case conversion</title>

          <p>Notice that regex is case sensitive. Often we want to match a word regardless of case. One approach to doing this is to first change everything to lower case and then proceeding ignoring case. As an example, note that one of the entries writes out numbers as words <c>Five foot eight inches</c>. Although not efficient, we could add 13 extra <c>str_replace</c> calls to convert <c>zero</c> to <c>0</c>, <c>one</c> to <c>1</c>, and so on. To avoid having to write two separate operations for <c>Zero</c> and <c>zero</c>, <c>One</c> and <c>one</c>, etc., we can use the <c>str_to_lower</c> function to make all works lower case first:</p>

          <sage language="r">
            <input>
s &lt;- c("Five feet eight inches")
str_to_lower(s)
            </input>
          </sage>

          <p>Other related functions are <c>str_to_upper</c> and <c>str_to_title</c>. We are now ready to define a procedure that converts all the problematic cases to inches.</p>

        </section>

        <section xml:id="sec-case-study-1-continued-putting-it-all-together">
          <title>Case study 1 continued: Putting it all together</title>

          <p>We are now ready to put it all together and wrangle our reported heights data to try to recover as many heights as possible. The code is complex, but we will break it down into parts.</p>

          <p>Let's see how many problematic entries we can recover with the approaches we covered in <xref ref="sec-regex"/>. We will first define a function that detects entries that are not reported as inches or centimeters:</p>

          <sage language="r">
            <input>
not_inches_or_cm &lt;- function(x, smallest = 50, tallest = 84){
  inches &lt;- suppressWarnings(as.numeric(x))
  is.na(inches) |
    !((inches &gt;= smallest &amp; inches &lt;= tallest) |
        (inches/2.54 &gt;= smallest &amp; inches/2.54 &lt;= tallest))
}
            </input>
          </sage>

          <p>We can see how many entries are not inches or centimeters:</p>

          <sage language="r">
            <input>
problems &lt;- reported_heights |&gt; 
  filter(not_inches_or_cm(height)) |&gt;
  pull(height)
length(problems)
            </input>
          </sage>

          <p>Let's see how many feet<c>'</c>inches format we can recover applying the finding from <xref ref="sec-regex"/>. Specifically we replace feet/foot/ft with <c>'</c>, we remove the word inches and its abbreviations, then rewrite similar patterns into the desired feet<c>'</c>inches pattern. Once this is done we see what proportion don't fit the desired pattern</p>

          <sage language="r">
            <input>
converted &lt;- problems |&gt; 
  str_replace("feet|foot|ft", "'") |&gt; 
  str_remove_all("inches|in|''|\"") |&gt;  
  str_replace("^([4-7])\\s*[,\\.\\s+]\\s*(\\d*)$", "\\1'\\2") 
index &lt;- str_detect(converted, "^[4-7]\\s*'\\s*\\d{1,2}$")
mean(!index)
            </input>
          </sage>

          <p>We see that a substantial proportion has not yet been fixed. Trial and error is a common approach to finding the regex pattern that satisfies all desired conditions. We can examine the remaining cases to try to decipher if new patterns we can use to fix them:</p>

          <sage language="r">
            <input>
converted[!index]
            </input>
          </sage>

          <p>We noticed that two students added <c>cm</c> and some entries have space at the end so we write incorporate this into our cleanup stage. We also notice that at least one entry wrote out numbers such as <c>Five foot eight inches</c>. We can use  the <c>words()</c> function in the <alert>english</alert> package to change these to actual numbers. In preparation for our final product, we define a function that cleans up previously noticed problems and these new ones:</p>

          <sage language="r">
            <input>
library(english)
cleanup &lt;- function(s){
  s &lt;- str_remove_all(s, "inches|in|''|\"|cm|and") |&gt; 
    str_trim() |&gt;
    str_to_lower()
  for (i in 0:11) {
    s &lt;- str_replace_all(s, words(i), as.character(i))
  }
  return(s)
}
            </input>
          </sage>

          <p>Many also notice that students measuring exactly 5 or 6 feet did not enter any inches, for example <c>6'</c>, and our pattern requires that inches be included, and that some entries are in meters and some of these use European decimals, for example <c>1.6</c> and <c>1,70</c>. So we create a function that add these corrections to those already identified as needed to reformat the entry as feet<c>'</c>inches:</p>

          <sage language="r">
            <input>
convert_format &lt;- function(s){
  s |&gt; str_replace("feet|foot|ft", "'") |&gt; 
    str_replace("^([4-7])\\s*[,\\.\\s+]\\s*(\\d*)$", "\\1'\\2") |&gt; 
    str_replace("^([56])'?$", "\\1'0") |&gt; 
    str_replace("^([12])\\s*,\\s*(\\d*)$", "\\1\\.\\2")
}
            </input>
          </sage>

          <p>Now we are ready to wrangle our reported heights dataset. The strategy is as follows:</p>

          <ol>
            <li><p>We start by defining a variable to keep a copy of the original entry, we then clean up and covert the <c>height</c> entry using the functions described above. </p></li>
            <li><p>We then use the <c>separate_wider_regex_</c> function to extract feet and inches when the entry matches our feet<c>'</c>inches format. </p></li>
            <li><p>We use a lookaround to make sure that entries that have numbers with no <c>'</c> following them don't match and return an <c>NA</c>. </p></li>
          <sage language="r">
            <input>
patterns &lt;- c(feet = "[4-7](?=\\s*'\\s*)", 
              "\\s*'\\s*", 
              inches = "\\d+\\.?\\d*")
smallest &lt;- 50
tallest &lt;- 84
new_heights &lt;- reported_heights |&gt; 
  mutate(original = height, 
         height = convert_format(cleanup(height))) |&gt;
  separate_wider_regex(height, patterns = patterns, 
                       too_few = "align_start", 
                       cols_remove = FALSE) |&gt; 
  mutate(across(c(height, feet, inches), as.numeric)) |&gt;
  mutate(guess = 12 * feet + inches) |&gt;
  mutate(height = case_when(
    is.na(height) ~ as.numeric(NA),
    between(height, smallest, tallest) ~ height,  #inches
    between(height/2.54, smallest, tallest) ~ height/2.54, #cm
    between(height*100/2.54, smallest, tallest) ~ height*100/2.54, #meters
    TRUE ~ as.numeric(NA))) |&gt;
  mutate(height = ifelse(is.na(height) &amp; 
                           inches &lt;= 12 &amp; between(guess, smallest, tallest),
                         guess, height)) |&gt;
  select(-feet, -inches, -guess)
            </input>
          </sage>

          </ol>

          <p>We see that we fix all but <c>sum(is.na(new_heights$height))</c> entries. You can see that these are mostly un-fixable:</p>

          <sage language="r">
            <input>
new_heights |&gt; filter(is.na(height)) |&gt; pull(original)
            </input>
          </sage>

          <p>You can review the ones we did fix by typing:</p>

          <sage language="r">
            <input>
#| eval: false
new_heights |&gt;
  filter(not_inches_or_cm(original)) |&gt;
  select(original, height) |&gt; 
  arrange(height) |&gt;
  View()
            </input>
          </sage>

          <p>A final observation is that if we look at the shortest students in our course:</p>

          <sage language="r">
            <input>
new_heights |&gt; arrange(height) |&gt; head(n = 6)
            </input>
          </sage>

          <p>We see heights of 50, 51, 52, and so on. These short heights are rare and it is likely that the students actually meant 5'0,  5'1, 5'2 and so on. Because we are not completely sure, we will leave them as reported. The object new_heights contains our final solution for this case study.</p>

        </section>

        <section xml:id="sec-case-study-2-extracting-tables-from-a-pdf">
          <title>Case study 2: extracting tables from a PDF</title>

          <p>One of the datasets provided in <alert>dslabs</alert> shows scientific funding rates by gender in the Netherlands:</p>

          <sage language="r">
            <input>
library(dslabs)
research_funding_rates |&gt; 
  select("discipline", "success_rates_men", "success_rates_women")
            </input>
          </sage>

          <p>The data comes from a paper published in the Proceedings of the National Academy of Science (PNAS), a widely read scientific journal. However, the data is not provided in a spreadsheet; it is in a table in a PDF document. Here is a screenshot of the table:</p>

          <figure>
            <image source="wrangling/img/pnas-table-s1.png"/>
          </figure>

          <p>(Source: Romy van der Lee and Naomi Ellemers, PNAS 2015 112 (40) 12349-12353.)</p>

          <p>We could extract the numbers by hand, but this could lead to human error. Instead, we can try to wrangle the data using R. We start by downloading the pdf document, then importing into R:</p>

          <sage language="r">
            <input>
library("pdftools")
temp_file &lt;- tempfile()
url &lt;- paste0("https://web.archive.org/web/20150927033124/",
              "https://www.pnas.org/content/suppl/2015/09/16/",
              "1510159112.DCSupplemental/pnas.201510159SI.pdf")
download.file(url, temp_file, mode = "wb")
txt &lt;- pdf_text(temp_file)
file.remove(temp_file)
            </input>
          </sage>

          <note>
            <p>The <c>mode = "wb"</c> argument is only necessary if using Microsoft Windows. On MacOs or Linux the default <c>mode = "w"</c> works. To understand this difference please refer to the <c>download.file</c> help file.</p>
          </note>

          <p>If we examine the object text, we notice that it is a character vector with an entry for each page. So we keep the page we want:</p>

          <sage language="r">
            <input>
raw_data_research_funding_rates &lt;- txt[2]
            </input>
          </sage>

          <p>The steps above can actually be skipped because we include this raw data in the <alert>dslabs</alert> package as well.</p>

          <p>Examining the object <c>raw_data_research_funding_rates</c> we see that it is a long string and each line on the page, including the table rows, are separated by the symbol for newline: <c>\n</c>. A first step in converting this into a data frame is to store rows separately in a way that will make them easy to access. For this we use the <c>str_split</c> function:</p>

          <sage language="r">
            <input>
tab &lt;- str_split(raw_data_research_funding_rates, "\n+")
            </input>
          </sage>

          <note>
            <p>On MacOS or Linux you can simply use <c>\n</c> as the separator. Microsoft Windows and macOS (which is based on Unix) use different conventions for line endings in text files and a result <c>raw_data_research_funding_rates</c> has more <c>\n</c> when using Windows.</p>
          </note>

          <p>Because we start off with just one string, we end up with a list with just one entry.</p>

          <sage language="r">
            <input>
tab &lt;- tab[[1]]
            </input>
          </sage>

          <p>By examining <c>tab</c> we see that the information for the column names is the third and fourth entries:</p>

          <sage language="r">
            <input>
the_names_1 &lt;- tab[3]
the_names_2 &lt;- tab[4]
            </input>
          </sage>

          <p>The first of these rows looks like this:</p>

          <sage language="r">
            <input>
cat(substr(the_names_1, 1, options()$width))
cat(substr(the_names_1, options()$width, nchar(the_names_1)))
            </input>
          </sage>

          <p>We want to create one vector with one name for each column. Using some of the functions we have just learned, we do this.</p>

          <p>Let's start with <c>the_names_1</c>, shown above. We want to remove the leading space and anything following the comma. We use regex for the latter. Then we can obtain the elements by splitting strings separated by space. We want to split only when there are 2 or more spaces to avoid splitting <c>Success rates</c>. So we use the regex <c>\\s{2,}</c></p>

          <sage language="r">
            <input>
the_names_1 &lt;- the_names_1 |&gt;
  str_trim() |&gt;
  str_replace_all(",\\s.", "") |&gt;
  str_split("\\s{2,}", simplify = TRUE)
the_names_1 
            </input>
          </sage>

          <p>Now we will look at <c>the_names_2</c>:</p>

          <sage language="r">
            <input>
cat(substr(the_names_2, 1, options()$width))
cat(substr(the_names_2, options()$width, nchar(the_names_2)))
            </input>
          </sage>

          <p>Here we want to trim the leading space and then split by space as we did for the first line:</p>

          <sage language="r">
            <input>
the_names_2 &lt;- the_names_2 |&gt;
  str_trim() |&gt;
  str_split("\\s+", simplify = TRUE)
the_names_2
            </input>
          </sage>

          <p>We can then join these to generate one name for each column:</p>

          <sage language="r">
            <input>
tmp_names &lt;- paste(rep(the_names_1, each = 3), the_names_2[-1], sep = "_")
the_names &lt;- c(the_names_2[1], tmp_names) |&gt;
  str_to_lower() |&gt;
  str_replace_all("\\s", "_")
the_names
            </input>
          </sage>

          <p>Now we are ready to get the actual data. By examining the <c>tab</c> object, we notice that the information is in lines 6 through 14. We can use <c>str_split</c> again to achieve our goal:</p>

          <sage language="r">
            <input>
new_research_funding_rates &lt;- tab[6:14] |&gt;
  str_trim() |&gt;
  str_split("\\s{2,}", simplify = TRUE) |&gt;
  data.frame() |&gt;
  setNames(the_names) |&gt;
  mutate(across(-1, parse_number))
new_research_funding_rates |&gt; as_tibble()
            </input>
          </sage>

          <p>We can see that the objects are identical:</p>

          <sage language="r">
            <input>
identical(research_funding_rates, new_research_funding_rates)
            </input>
          </sage>

        </section>

        <section xml:id="sec-recode">
          <title>Renaming levels</title>

          <p>Another common operation involving strings is renaming the levels of  of a categorical variables. Let's say you have really long names for your levels. If you will be displaying them in plots, you might want to use shorter versions of these names. For example, in character vectors with country names, you might want to change "United States of America" to "USA" and "United Kingdom" to UK, and so on.</p>

          <p>Rather than changing each entry, a more efficient approach is to change the levels.</p>

          <p>Here is an example that shows how to rename countries with long names:</p>

          <sage language="r">
            <input>
library(dslabs)
            </input>
          </sage>

          <p>Suppose we want to show life expectancy time series by country for the Caribbean. If we make this plot</p>

          <sage language="r">
            <input>
gapminder |&gt; 
  filter(region == "Caribbean") |&gt;
  ggplot(aes(year, life_expectancy, color = country)) +
  geom_line()
            </input>
          </sage>

          <p>we see that the legend takes up much of the plot because we have four countries with names longer than 12 characters. We can rename these levels using the <c>case_when</c> function:</p>

          <sage language="r">
            <input>
x &lt;- levels(gapminder$country)
levels(gapminder$country) &lt;- case_when(
  x == "Antigua and Barbuda" ~ "Barbuda",
  x == "Dominican Republic" ~ "DR",
  x == "St. Vincent and the Grenadines" ~ "St. Vincent",
  x == "Trinidad and Tobago" ~ "Trinidad",
  .default = x)
gapminder |&gt; 
  filter(region == "Caribbean") |&gt;
  ggplot(aes(year, life_expectancy, color = country)) +
  geom_line()
            </input>
          </sage>

          <p>We can instead use the <c>fct_recode</c> function in the <alert>forcats</alert> package:</p>

          <sage language="r">
            <input>
#| eval: false
library(forcats)
gapminder$country &lt;- 
  fct_recode(gapminder$country, 
             "Barbuda" = "Antigua and Barbuda",
             "DR" = "Dominican Republic",
             "St. Vincent" = "St. Vincent and the Grenadines",
             "Trinidad" = "Trinidad and Tobago")
            </input>
          </sage>

        </section>

        <section xml:id="sec-string-processing-exercises">
          <title>Exercises</title>

          <ol>
            <li><p>Complete all lessons and exercises in the RegexOne</p></li>
          </ol>

          <p>online interactive tutorial.</p>

          <ol>
            <li><p>In the <c>extdata</c> directory of the <alert>dslabs</alert> package, you will find</p></li>
          </ol>

          <p>a PDF file containing daily mortality data for Puerto Rico from Jan 1, 2015 to May 31, 2018. You can find the file like this:</p>

          <sage language="r">
            <input>
fn &lt;- system.file("extdata", "RD-Mortality-Report_2015-18-180531.pdf",
                  package="dslabs")
            </input>
          </sage>

          <p>Find and open the file or open it directly from RStudio. On a Mac, you can type:</p>

          <sage language="r">
            <input>
system2("open", args = fn)
            </input>
          </sage>

          <p>and on Windows, you can type:</p>

          <sage language="r">
            <input>
system("cmd.exe", input = paste("start", fn))
            </input>
          </sage>

          <p>Which of the following best describes this file:</p>

          <p>a.  It is a table. Extracting the data will be easy. b.  It is a report written in prose. Extracting the data will be impossible. c.  It is a report combining graphs and tables. Extracting the data seems possible. d.  It shows graphs of the data. Extracting the data will be difficult.</p>

          <ol>
            <li><p>We are going to create a tidy dataset with each row representing one</p></li>
          </ol>

          <p>observation. The variables in this dataset will be year, month, day, and deaths. Start by installing and loading the <alert>pdftools</alert> package:</p>

          <sage language="r">
            <input>
install.packages("pdftools")
library(pdftools)
            </input>
          </sage>

          <p>Now read-in <c>fn</c> using the <c>pdf_text</c> function and store the results in an object called <c>txt</c>. Which of the following best describes what you see in <c>txt</c>?</p>

          <p>a.  A table with the mortality data. b.  A character string of length 12. Each entry represents the text in each page. The mortality data is in there somewhere. c.  A character string with one entry containing all the information in the PDF file. d.  An html document.</p>

          <ol>
            <li><p>Extract the ninth page of the PDF file from the object <c>txt</c>, then</p></li>
          </ol>

          <p>use the <c>str_split</c> from the <alert>stringr</alert> package so that you have each line in a different entry. Call this string vector <c>s</c>. Then look at the result and choose the one that best describes what you see.</p>

          <p>a.  It is an empty string. b.  I can see the figure shown in page 1. c.  It is a tidy table. d.  I can see the table! But there is a bunch of other stuff we need to get rid of.</p>

          <ol>
            <li><p>What kind of object is <c>s</c> and how many entries does it have?</p></li>
            <li><p>We see that the output is a list with one component. Redefine <c>s</c> to</p></li>
          </ol>

          <p>be the first entry of the list. What kind of object is <c>s</c> and how many entries does it have?</p>

          <ol>
            <li><p>When inspecting the string we obtained above, we see a common</p></li>
          </ol>

          <p>problem: white space before and after the other characters. Trimming is a common first step in string processing. These extra spaces will eventually make splitting the strings hard so we start by removing them. We learned about the command <c>str_trim</c> that removes spaces at the start or end of the strings. Use this function to trim <c>s</c>.</p>

          <ol>
            <li><p>We want to extract the numbers from the strings stored in <c>s</c>.</p></li>
          </ol>

          <p>However, there are many non-numeric characters that will get in the way. We can remove these, but before doing this we want to preserve the string with the column header, which includes the month abbreviation. Use the <c>str_which</c> function to find the rows with a header. Save these results to <c>header_index</c>. Hint: find the first string that matches the pattern <c>2015</c> using the <c>str_which</c> function.</p>

          <ol>
            <li><p>Now we are going to define two objects: <c>month</c> will store the month</p></li>
          </ol>

          <p>and <c>header</c> will store the column names. Identify which row contains the header of the table. Save the content of the row into an object called <c>header</c>, then use <c>str_split</c> to help define the two objects we need. Hints: the separator here is one or more spaces. Also, consider using the <c>simplify</c> argument.</p>

          <ol>
            <li><p>Notice that towards the end of the page you see a <em>totals</em> row</p></li>
          </ol>

          <p>followed by rows with other summary statistics. Create an object called <c>tail_index</c> with the index of the <em>totals</em> entry.</p>

          <ol>
            <li><p>Because our PDF page includes graphs with numbers, some of our rows</p></li>
          </ol>

          <p>have just one number (from the y-axis of the plot). Use the <c>str_count</c> function to create an object <c>n</c> with the number of numbers in each each row. Hint: you can write a regex for number like this <c>\\d+</c>.</p>

          <ol>
            <li><p>We are now ready to remove entries from rows that we know we don't</p></li>
          </ol>

          <p>need. The entry <c>header_index</c> and everything before it should be removed. Entries for which <c>n</c> is 1 should also be removed, and the entry <c>tail_index</c> and everything that comes after it should be removed as well.</p>

          <ol>
            <li><p>Now we are ready to remove all the non-numeric entries. Do this</p></li>
          </ol>

          <p>using regex and the <c>str_remove_all</c> function. Hint: remember that in regex, using the upper case version of a special character usually means the opposite. So <c>\\D</c> means "not a digit". Remember you also want to keep spaces.</p>

          <ol>
            <li><p>To convert the strings into a table, use the <c>str_split_fixed</c></p></li>
          </ol>

          <p>function. Convert <c>s</c> into a data matrix with just the day and death count data. Hints: note that the separator is one or more spaces. Make the argument <c>n</c> a value that limits the number of columns to the values in the 4 columns and the last column captures all the extra stuff. Then keep only the first four columns.</p>

          <ol>
            <li><p>Now you are almost ready to finish. Add column names to the matrix,</p></li>
          </ol>

          <p>including one called <c>day</c>. Also, add a column with the month. Call the resulting object <c>dat</c>. Finally, make sure the day is an integer not a character. Hint: use only the first five columns.</p>

          <ol>
            <li><p>Now finish it up by tidying <c>tab</c> with the <c>pivot_longer</c></p></li>
          </ol>

          <p>function.</p>

          <ol>
            <li><p>Make a plot of deaths versus day with color to denote year. Exclude</p></li>
            <li><p>Now that we have wrangled this data step-by-step, put it all</p></li>
          </ol>

          <p>together in one R chunk, using the pipe as much as possible. Hint: first define the indexes, then write one line of code that does all the string processing.</p>

          <ol>
            <li><p>Advanced: let's return to the MLB Payroll example from the web</p></li>
          </ol>

          <p>scraping section. Use what you have learned in the web scraping and string processing chapters to extract the payroll for the New York Yankees, Boston Red Sox, and Oakland A's and plot them as a function of time.</p>

        </section>
        
      </chapter>

      <chapter xml:id="ch-text-analysis">
        <title>Text analysis</title>
        
          <p>With the exception of labels used to represent categorical data, we have focused on numerical data. But in many applications, data starts as text. Well-known examples are spam filtering, cyber-crime prevention, counter-terrorism and sentiment analysis. In all these cases, the raw data is composed of free form text. Our task is to extract insights from these data. In this section, we learn how to generate useful numerical summaries from text data to which we can apply some of the powerful data visualization and analysis techniques we have learned.</p>

        <section xml:id="sec-case-study-trump-tweets">
          <title>Case study: Trump tweets</title>

          <p>During the 2016 US presidential election, then candidate Donald J. Trump used his twitter account as a way to communicate with potential voters. On August 6, 2016, Todd Vaziri tweeted about Trump that "Every non-hyperbolic tweet is from iPhone (his staff). Every hyperbolic tweet is from Android (from him)." David Robinson conducted an analysis to determine if data supported this assertion. Here, we go through David's analysis to learn some of the basics of text analysis. To learn more about text analysis in R, we recommend the Text Mining with R book by Julia Silge and David Robinson.</p>

          <sage language="r">
            <input>
set.seed(2002)
            </input>
          </sage>

          <p>We will use the following libraries:</p>

          <sage language="r">
            <input>
library(tidyverse)
library(scales)
library(tidytext)
library(textdata)
library(dslabs)
            </input>
          </sage>

          <p>X, formerly known as twitter, provides an API that permits downloading tweets. Brendan Brown runs the trump archive, which compiles tweet data from Trump's account. The <alert>dslabs</alert> package includes tweets from the following range:</p>

          <sage language="r">
            <input>
range(trump_tweets$created_at)
            </input>
          </sage>

          <p>The data frame includes the the following variables:</p>

          <sage language="r">
            <input>
names(trump_tweets)
            </input>
          </sage>

          <p>The help file <c>?trump_tweets</c> provides details on what each variable represents. The actual tweets are in the <c>text</c> variable:</p>

          <sage language="r">
            <input>
trump_tweets$text[16413] |&gt; str_wrap(width = options()$width) |&gt; cat()
            </input>
          </sage>

          <p>and the source variable tells us which device was used to compose and upload each tweet:</p>

          <sage language="r">
            <input>
trump_tweets |&gt; count(source) |&gt; arrange(desc(n)) |&gt; head(5)
            </input>
          </sage>

          <p>We are interested in what happened during the 2016 campaign, so for this analysis we will focus on what was tweeted between the day Trump announced his campaign and election day. We define the following table containing just the tweets from that time period. We remove the <c>Twitter for</c> part of the source, only keep tweets from Android or iPhone, and filter out retweets.</p>

          <sage language="r">
            <input>
campaign_tweets &lt;- trump_tweets |&gt; 
  filter(source %in% paste("Twitter for", c("Android", "iPhone")) &amp;
           created_at &gt;= ymd("2015-06-17") &amp; 
           created_at &lt; ymd("2016-11-08")) |&gt;
  mutate(source = str_remove(source, "Twitter for ")) |&gt;
  filter(!is_retweet) |&gt;
  arrange(created_at) |&gt; 
  as_tibble()
            </input>
          </sage>

          <p>We can now use data visualization to explore the possibility that two different groups were tweeting from these devices. For each tweet, we will extract the hour, Eastern Standard Time (EST), it was tweeted and then compute the proportion of tweets tweeted at each hour for each device:</p>

          <sage language="r">
            <input>
campaign_tweets |&gt;
  mutate(hour = hour(with_tz(created_at, "EST"))) |&gt;
  count(source, hour) |&gt;
  group_by(source) |&gt;
  mutate(percent = n / sum(n)) |&gt;
  ungroup() |&gt;
  ggplot(aes(hour, percent, color = source)) +
  geom_line() +
  geom_point() +
  scale_y_continuous(labels = percent_format()) +
  labs(x = "Hour of day (EST)", y = "% of tweets", color = "")
            </input>
          </sage>

          <p>We notice a big peak for the Android in the early hours of the morning, between 6 and 8 AM. There seems to be a clear difference in these patterns. We will therefore assume that two different entities are using these two devices.</p>

          <p>We will now study how the text of the tweets differ when we compare Android to iPhone. To do this, we introduce the <alert>tidytext</alert> package.</p>

        </section>

        <section xml:id="sec-text-as-data">
          <title>Text as data</title>

          <p>The <alert>tidytext</alert> package helps us convert free form text into a tidy table. Having the data in this format greatly facilitates data visualization and the use of statistical techniques.</p>

          <p>The main function needed to achieve this is <c>unnest_tokens</c>. A <em>token</em> refers to a unit that we are considering to be a data point. The most common <em>token</em> will be words, but they can also be single characters, n-grams, sentences, lines, or a pattern defined by a regex. The function will take a vector of strings and extract the tokens so that each one gets a row in the new table. Here is a simple example:</p>

          <sage language="r">
            <input>
poem &lt;- c("Roses are red,", "Violets are blue,", 
          "Sugar is sweet,", "And so are you.")
example &lt;- tibble(line = c(1, 2, 3, 4),
                      text = poem)
example
example |&gt; unnest_tokens(word, text)
            </input>
          </sage>

          <p>Now let's look at Trump's tweets. We will look at tweet number 3008 because it will later permit us to illustrate a couple of points:</p>

          <sage language="r">
            <input>
i &lt;- 3008
campaign_tweets$text[i] |&gt; str_wrap(width = 65) |&gt; cat()
campaign_tweets[i,] |&gt; 
  unnest_tokens(word, text) |&gt;
  pull(word) 
            </input>
          </sage>

          <p>Note that the function tries to convert tokens into words. A minor adjustment is to remove the links to pictures:</p>

          <sage language="r">
            <input>
links_to_pics &lt;- "https://t.co/[A-Za-z\\d]+|&amp;amp;"
campaign_tweets[i,] |&gt; 
  mutate(text = str_remove_all(text, links_to_pics))  |&gt;
  unnest_tokens(word, text) |&gt;
  pull(word)
            </input>
          </sage>

          <p>Now we are now ready to extract the words from all our tweets.</p>

          <sage language="r">
            <input>
tweet_words &lt;- campaign_tweets |&gt; 
  mutate(text = str_remove_all(text, links_to_pics))  |&gt;
  unnest_tokens(word, text)
            </input>
          </sage>

          <p>And we can now answer questions such as "what are the most commonly used words?":</p>

          <sage language="r">
            <input>
tweet_words |&gt; 
  count(word) |&gt;
  arrange(desc(n))
            </input>
          </sage>

          <p>It is not surprising that these are the top words, which are not informative. The <em>tidytext</em> package has a database of these commonly used words, referred to as <em>stop words</em>, in text analysis:</p>

          <sage language="r">
            <input>
head(stop_words)
            </input>
          </sage>

          <p>If we filter out rows representing stop words with <c>filter(!word %in% stop_words$word)</c>:</p>

          <sage language="r">
            <input>
tweet_words &lt;- campaign_tweets |&gt; 
  mutate(text = str_remove_all(text, links_to_pics))  |&gt;
  unnest_tokens(word, text) |&gt;
  filter(!word %in% stop_words$word ) 
            </input>
          </sage>

          <p>we end up with a much more informative set of top 10 tweeted words:</p>

          <sage language="r">
            <input>
tweet_words |&gt; 
  count(word) |&gt;
  slice_max(n, n = 10) |&gt;
  arrange(desc(n))
            </input>
          </sage>

          <p>Some exploration of the resulting words (not shown here) reveals a couple of unwanted characteristics in our tokens. First, some of our tokens are just numbers (years, for example). We want to remove these and we can find them using the regex <c>^\d+$</c>. Second, some of our tokens come from a quote and they start with <c>'</c>. We want to remove the <c>'</c> when it is at the start of a word so we will just <c>str_replace</c>. We add these two lines to the code above to generate our final table:</p>

          <sage language="r">
            <input>
tweet_words &lt;- campaign_tweets |&gt; 
  mutate(text = str_remove_all(text, links_to_pics))  |&gt;
  unnest_tokens(word, text) |&gt;
  filter(!word %in% stop_words$word &amp;
           !str_detect(word, "^\\d+$")) |&gt;
  mutate(word = str_replace(word, "^'", ""))
            </input>
          </sage>

          <p>Now that we have all our words in a table, along with information about what device was used to compose the tweet they came from, we can start exploring which words are more common when comparing Android to iPhone.</p>

          <p>For each word, we want to know if it is more likely to come from an Android tweet or an iPhone tweet. We therefore compute, for each word, its frequency among words tweeted from Android and iPhone, respectively and then derive the ratio of these proportions (Android proportion divided by iPhone proportion). Because some words are infrequent, we apply the continuity correction described in <xref ref="sec-log-transform"/>:</p>

          <sage language="r">
            <input>
android_vs_iphone &lt;- tweet_words |&gt;
  count(word, source) |&gt;
  pivot_wider(names_from = "source", values_from = "n", values_fill = 0) |&gt;
  mutate(p_a = (Android + 0.5)/(sum(Android) + 0.5), 
         p_i = (iPhone + 0.5)/(sum(iPhone) + 0.5),  
         ratio = p_a / p_i)
            </input>
          </sage>

          <p>For words appearing at least 100 times in total, here are the highest percent differences for Android</p>

          <sage language="r">
            <input>
android_vs_iphone |&gt; filter(Android + iPhone &gt;= 100) |&gt; arrange(desc(ratio))
            </input>
          </sage>

          <p>and the top for iPhone:</p>

          <sage language="r">
            <input>
android_vs_iphone |&gt; filter(Android + iPhone &gt;= 100) |&gt;  arrange(ratio)
            </input>
          </sage>

          <p>We already see somewhat of a pattern in the types of words that are being tweeted more from one device versus the other. However, we are not interested in specific words but rather in the tone. Vaziri's assertion is that the Android tweets are more hyperbolic. So how can we check this with data? <em>Hyperbolic</em> is a hard sentiment to extract from words as it relies on interpreting phrases. However, words can be associated to more basic sentiment such as anger, fear, joy, and surprise. In the next section, we demonstrate basic sentiment analysis.</p>

        </section>

        <section xml:id="sec-sentiment-analysis">
          <title>Sentiment analysis</title>

          <p>In sentiment analysis, we assign a word to one or more "sentiments". Although this approach will miss context-dependent sentiments, such as sarcasm, when performed on large numbers of words, summaries can provide insights.</p>

          <p>The first step in sentiment analysis is to assign a sentiment to each word. As we demonstrate, the <alert>tidytext</alert> package includes several maps or lexicons. The <alert>textdata</alert> package includes several of these lexicons.</p>

          <p>The <c>bing</c> lexicon divides words into <c>positive</c> and <c>negative</c> sentiments. We can see this using the <em>tidytext</em> function <c>get_sentiments</c>:</p>

          <sage language="r">
            <input>
get_sentiments("bing")
            </input>
          </sage>

          <p>The <c>AFINN</c> lexicon assigns a score between -5 and 5, with -5 the most negative and 5 the most positive. Note that this lexicon needs to be downloaded the first time you call the function <c>get_sentiment</c>:</p>

          <sage language="r">
            <input>
get_sentiments("afinn")
            </input>
          </sage>

          <p>The <c>nrc</c> lexicon provide several different sentiments. Note that this also has to be downloaded the first time you use it.</p>

          <sage language="r">
            <input>
get_sentiments("nrc") |&gt; count(sentiment)
            </input>
          </sage>

          <p>For our analysis, we are interested in exploring the different sentiments of each tweet so we will use the <c>nrc</c> lexicon:</p>

          <sage language="r">
            <input>
nrc &lt;- get_sentiments("nrc") |&gt; select(word, sentiment)
            </input>
          </sage>

          <p>We can combine the words and sentiments using <c>inner_join</c>, which will only keep words associated with a sentiment. Here are 5 random words extracted from the tweets:</p>

          <sage language="r">
            <input>
tweet_words |&gt; inner_join(nrc, by = "word", relationship = "many-to-many") |&gt; 
  select(source, word, sentiment) |&gt; 
  sample_n(5)
            </input>
          </sage>

          <note>
            <p><c>relationship = "many-to-many"</c> is added to address a warning that arises from <c>left_join</c> detecting an "unexpected many-to-many relationship". However, this behavior is actually expected in this context because many words have multiple sentiments associated with them.</p>
          </note>

          <p>Now we are ready to perform a quantitative analysis comparing Android and iPhone by comparing the sentiments of the tweets posted from each device. Here we could perform a tweet-by-tweet analysis, assigning a sentiment to each tweet. However, this will be challenging since each tweet will have several sentiments attached to it, one for each word appearing in the lexicon. For illustrative purposes, we will perform a much simpler analysis: we will count and compare the frequencies of each sentiment appearing in each device.</p>

          <sage language="r">
            <input>
sentiment_counts &lt;- tweet_words |&gt;
  left_join(nrc, by = "word", relationship = "many-to-many") |&gt;
  count(source, sentiment) |&gt;
  pivot_wider(names_from = "source", values_from = "n") |&gt;
  mutate(sentiment = replace_na(sentiment, replace = "none"))
            </input>
          </sage>

          <p>For each sentiment, we calculate its proportion relative to the total responses for  Android and iPhone, respectively, and derive the ratio of these proportions (Android proportion divided by iPhone proportion).</p>

          <sage language="r">
            <input>
sentiment_counts &lt;- sentiment_counts |&gt;
  mutate(p_a = Android/sum(Android), p_i = iPhone/sum(iPhone), ratio = p_a/p_i) |&gt; 
  arrange(desc(ratio))
sentiment_counts
            </input>
          </sage>

          <p>So we do see some differences and the order is interesting: the largest three sentiments are disgust, anger, and negative!</p>

          <p>If we are interested in exploring which specific words are driving these differences, we can refer back to our <c>android_vs_iphone</c> object. For each sentiment we show the 10 largest ratios, in either direction. We exclude words appearing less than 10 times total.</p>

          <sage language="r">
            <input>
ordered_levels &lt;- sentiment_counts$sentiment

android_vs_iphone |&gt;
  filter(Android + iPhone &gt;= 10) |&gt;
  inner_join(nrc, by = "word") |&gt;
  mutate(sentiment = factor(sentiment, levels = sentiment_counts$sentiment)) |&gt;
  group_by(sentiment) |&gt;
  slice_max(abs(log(ratio)), n = 10) |&gt;
  ungroup() |&gt; 
  mutate(word = reorder(word, -ratio)) |&gt;
  ggplot(aes(word, ratio, fill = ratio &lt; 1)) +
  geom_col(show.legend = FALSE) +
  scale_y_log10() +
  facet_wrap(~sentiment, scales = "free_x", nrow = 2) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) 
            </input>
          </sage>

          <p>This is just a simple example of the many analyses one can perform with tidytext. To learn more, we again recommend the Tidy Text Mining book.</p>

        </section>

        <section xml:id="sec-text-analysis-exercises">
          <title>Exercises</title>

          <p>Project Gutenberg is a digital archive of public domain books. The R package <alert>gutenbergr</alert> facilitates the importation of these texts into R.</p>

          <p>You can install and load by typing:</p>

          <sage language="r">
            <input>
install.packages("gutenbergr")
library(gutenbergr)
            </input>
          </sage>

          <p>You can see the books that are available like this:</p>

          <sage language="r">
            <input>
gutenberg_metadata
            </input>
          </sage>

          <ol>
            <li><p>Use <c>str_detect</c> to find the ID of the novel <em>Pride and Prejudice</em>.</p></li>
            <li><p>We notice that there are several versions. The <c>gutenberg_works()</c> function filters this table to remove replicates and include only English language works. Read the help file and use this function to find the ID for <em>Pride and Prejudice</em>.</p></li>
            <li><p>Use the <c>gutenberg_download</c> function to download the text for Pride and Prejudice. Save it to an object called <c>book</c>.</p></li>
            <li><p>Use the <alert>tidytext</alert> package to create a tidy table with all the words in the text. Save the table in an object called <c>words</c></p></li>
            <li><p>We will later make a plot of sentiment versus location in the book. For this, it will be useful to add a column with the word number to the table.</p></li>
            <li><p>Remove the stop words and numbers from the <c>words</c> object. Hint: use the <c>anti_join</c>.</p></li>
            <li><p>Now use the <c>AFINN</c> lexicon to assign a sentiment value to each word.</p></li>
            <li><p>Make a plot of sentiment score versus location in the book and add a smoother.</p></li>
            <li><p>Assume there are 300 words per page. Convert the locations to pages and then compute the average sentiment in each page. Plot that average score by page. Add a smoother that appears to go through data.</p></li>
          </ol>

        </section>
        
      </chapter>

    </part>
